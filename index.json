
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"沈凡凡，男，博士，副教授，硕士研究生导师，润泽学者，中国计算机学会高级会员，毕业于武汉大学计算机软件与理论专业，CCF信息存储技术专业委员会执行委员，CCF嵌入式系统专业委员会执行委员，CCF体系结构专业委员会委员，江苏省计算机学会计算机系统结构专业委员会委员、江苏省计算机学会计算机应用专业委员会委员。主持国家自然科学基金1项，省部级课题3项，参与国家自然科学基金、省部级项目多项。在《计算机学报》、《软件学报》、《计算机研究与发展》、《电子学报》、TC、SUPE、Cluster、CJE等国内外重要学术刊物上发表论文20余篇。担任国家自然科学基金项目评审专家、江苏省科技咨询专家、广东省科技咨询专家、山东省科技咨询专家等。主要讲授《操作系统》、《大数据存储技术》、《计算机系统基础》、《高等计算机系统结构》等课程。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1712326954,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"沈凡凡，男，博士，副教授，硕士研究生导师，润泽学者，中国计算机学会高级会员，毕业于武汉大学计算机软件与理论专业，CCF信息存储技术专业委员会执行委员，CCF嵌入式系统专业委员会执行委员，CCF体系结构专业委员会委员，江苏省计算机学会计算机系统结构专业委员会委员、江苏省计算机学会计算机应用专业委员会委员。主持国家自然科学基金1项，省部级课题3项，参与国家自然科学基金、省部级项目多项。在《计算机学报》、《软件学报》、《计算机研究与发展》、《电子学报》、TC、SUPE、Cluster、CJE等国内外重要学术刊物上发表论文20余篇。担任国家自然科学基金项目评审专家、江苏省科技咨询专家、广东省科技咨询专家、山东省科技咨询专家等。主要讲授《操作系统》、《大数据存储技术》、《计算机系统基础》、《高等计算机系统结构》等课程。","tags":null,"title":"沈凡凡","type":"authors"},{"authors":null,"categories":null,"content":"1.安装步骤 下载地址：https://www.mongodb.com/download-center/community 版本4.4或更高版本； 或者网盘下载：https://pan.baidu.com/s/15KwMqxcVFi8D6BpMBKNQkA?pwd=abt7 提取码: abt7 安装方法参考：https://www.runoob.com/mongodb/mongodb-window-install.html 安装过程中不要勾选MongoDB Compass（可视化环境），MongoDB单独安装。 2.配置数据和日志文件目录（自定义） 创建数据目录：D:\\mongodb\\data\\db 创建日志目录：D:\\mongodb\\data\\log 创建日志文件：D:\\mongodb\\data\\log\\mongodb.log 3.安装成功与否测试 启动服务器：C:\\Program Files\\MongoDB\\Server\\4.4\\bin\u0026gt;.\\mongod.exe –dbpath d:\\mongodb\\data\\db 看到日志倒数第二行：waiting for connections on port 27017 浏览器输入：http://localhost:27017/ 显示It looks like you are … 出现上述情况，说明安装正常 ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1708766632,"objectID":"cf9ddac390693f94948e13899dc3907e","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter1/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter1/","section":"courses","summary":"Blah, blah, blah...","tags":null,"title":"第1章 初识MongoDB","type":"book"},{"authors":["沈凡凡"],"categories":null,"content":"一、课程介绍 MongoDB在文档型数据库中排名第一。本课程是数据科学与大数据技术专业学生必须学习和掌握的基础课程，是一门理论与实践相结合的专业主干课。注重培养学生的自主学习和动手操作能力。大数据存储技术是海量数据存储的基础和支撑，它采用分布式计算架构方式，对海量数据提供数据存储和业务访问功能，主要讲授大数据存储MongoDB、CRUD操作、索引、聚集分析、wiredtriger存储引擎、复制集、分片集群、分布式文件存储系统、管理与监控、权限管理和应用实践。通过本课程的学习，学生能够掌握大数据技术的基本概念、基本原理、设计方法和实现技术。具备分析和实现海量数据的分布式存储的基本能力。培养学生的工匠意识，引导学生运用唯物主义辩证法分析和解决问题的能力。\n感谢“阿里云计算有限公司”对本课程的大力支持！\n感谢李晓涵、倪可欣、谢金龙、尚祥枝等同学编写在线教程！\n二、课程资源 2024年课件PPT地址，历史：2023年课件PPT地址 参考教材： 1.MongoDB核心原理与实践，郭远威，电子工业出版社 2.大数据存储MongoDB实战指南，郭远威，人民邮电出版社； 3.MongoDB权威指南，人民邮电出版社，香农·布拉德肖（Shannon Bradshaw） 著，牟天垒，王明辉 译。 数字化资源： MongoDB官方文档手册； MongoDB的教程网站； Mongodb开源代码 三、课程考核方式 平时情况：20%\n大作业：20%\n期末考试：60%\n四、教学计划 2024年春授课时间（1-17周） 2022级数据科学1班，周1第1-2，文心楼204； 2022级数据科学2班，周1第3-4，文心楼203； 每章对应的PPT课件在这里，2024年课件PPT地址 Lesson Number 章节 内容 备注 1 第1章 初识MongoDB MongoDB的发展与现状、关键特性、安装部署、重要进程 作业1：安装环境 2 第2章 CRUD操作 插入操作、删除操作、修改操作 掌握操作语法 3 第2章 CRUD操作 查询操作 作业2 4 第3章 索引 单字段索引、复合索引、多键索引、索引管理、查询优化 作业3 5 第4章 聚集操作 简单聚集函数，管道聚集，MapReduce编程 作业4 6 第5章 WiredTiger存储引擎 存储引擎的数据结构、原理 7 第6章 复制集 复制集概述、部署一个复制集 8 第6章 复制集 复制集工作机制 作业5 9 第7章 分片集群 分片集群的部署架构、手动部署一个分片集群 10 第7章 分片集群 分片集群的工作机制 作业6，大作业 11 第8章 分布式文件存储 原理、大小文件存储 12 第7章和第8章实验练习 实验练习 五、如何科学的提问？ 一、实验练习过程中，会遇到各种各样的bug，请不要怕。在提问之前，请仔细阅读How-To-Ask-Questions-The-Smart-Way提问的智慧和Stop-Ask-Questions-The-Stupid-Ways/这两篇文章。这两篇文章并不是为了故意浪费大家的时间, 也不是为了禁止大家提出任何问题, 而是为了让大家知道\u0026#34;什么是正确的\u0026#34;. 当你愿意为这些\u0026#34;正确的做法\u0026#34;去努力, 并且尝试用专业的方式提出问题的时候, 你就已经迈出了成为\u0026#34;成为专业人士\u0026#34;的第一步1 。\n二、如果都没有解决，向其他人提问的时候该这样描述：\n1.我已经尝试过哪些方案？但是依然报错。 2.我的尝试过程描述、操作截图、报错截图。 三、提问的套路图如下： 六、常见问题解决方法 1.我喜欢最新版本的软件，我就直接官网下载安装，可以吗？\n回答：编程能力强，能自我解决问题的，强烈建议用新版本。如果碰到问题，不太会独立解决，建议按照课程PPT的版本来，因为新版本肯定和旧版本有细微的差距。\n2.我怎么运行不出PPT的结果？我的操作怎么报错？\n回答：请仔细读懂PPT语句的含义，认真学习语法规则，检查自己是否敲错。少空格，单词错误，漏字符等等。\n3.我写的命令或查询语句为什么不能成功？\n回答：请检查命令是否书写正确？命令的路径是否正确？查询语句的语法是否正确？是否查看官方文档的语法规则？\n参考(如何科学地提问)) ↩︎\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1715594529,"objectID":"75838ad6b9cb206a80f426854cafe6de","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/bigdatastorage/","section":"courses","summary":"本课程是数据科学与大数据技术专业学生必须学习和掌握的基础课程，是一门理论与实践相结合的专业主干课。注重培养学生的自主学习和动手操作能力。大数据存储技术是海量数据存储的基础和支撑，它采用分布式计算架构方式，对海量数据提供数据存储和业务访问功能。","tags":null,"title":"《大数据存储技术》课程","type":"book"},{"authors":["沈凡凡"],"categories":null,"content":"一、课程介绍 《操作系统》课程是计算机考研408指定课程。操作系统是计算机系统的指挥中心，它既是系统中各种资源的管理者，又是服务的提供者。操作系统在计算机系统中所处的地位和作用决定本课程在计算机学科课程中特殊重要的核心位置。本课程主要讲授操作系统的基本概念、基本原理、设计方法和实现技术，包括：操作系统概述、进程线程与作业、中断与处理机调度、互斥同步、死锁、存储管理、输入输出系统、文件系统等内容。\n二、课程资源 updating：2023年操作系统课件PPT，配套练习题库 教材：计算机操作系统（慕课版），汤小丹 王红玲 姜华 汤子瀛编著，人民邮电出版社 本书官方视频资源：1.官方全书慕课视频(新书的封底有刮刮卡激活码)，2.B站官方教学视频王红玲主讲 MIT神级OS课程，强烈推荐学习：operating systems 6.828 上海交通大学陈海波老师，华为操作系统首席科学家，专注操作系统研究，IPADS实验室，教材与实验：操作系统原理与实现，建议自学完成实验部分 Linux命令大全，著名的操作系统专家Andrew S. Tanenbaum的个人网站 三、课程考核方式 课堂表现和作业：20%\n期中测试：20%\n期末考试：60%\n四、教学计划 每章对应的PPT课件在这里，2023年课件PPT地址\nLesson Number 章节 内容 备注 1 第1章 操作系统引论1.1-1.5节 第1章思维导图 操作系统的目标和作用、操作系统的发展过程、操作系统的基本特性、操作系统的主要功能、操作系统的结构设计 2 第1章 操作系统引论1.6节1.7节\n第2章 进程描述与控制 2.1-2.4节\n第2章思维导图 前趋图、进程的描述、控制、通信 第1章作业，课后1，2，25 3 第2章 进程描述与控制 2.5-2.6节\n第3章 处理机调度与死锁 3.1-3.2节\n第3章思维导图 线程的基本概念和实现，处理机调度概述，调度算法 第2章作业，1，2，21 4 第3章 处理机调度与死锁 3.3-3.7节 实时调度，死锁，预防死锁，避免死锁 5 第3章 处理机调度与死锁 3.8节\n第4章 进程同步 4.1-4.5节\n第4章思维导图 死锁的检测与解除，进程同步的基本概念，软件同步机制，硬件同步机制，信号量机制，管程机制 第3章作业，课后1，2，20，22 6 第4章 进程同步 4.6-4.7节\n第5章 存储器管理5.1-5.2节\n第5章思维导图 经典进程的同步问题、Linux进程同步机制，存储器的层次结构，程序的装入和链接。 第4章作业，课后1，2，13，15，16 7 第5章 存储器管理5.3-5.5\n第5章思维导图 对换与覆盖、连续分配存储管理方式、分页存储管理方式 8 第5章 存储器管理5.6-5.7\n第5章思维导图\n第6章 虚拟存储器6.1-6.3 第6章思维导图 分段存储管理方式、IA-32/x86-64内存管理、虚拟存储器概述、请求分页存储管理方式、页面置换算法 第5章作业，课后15，18 9 第6章 虚拟存储器6.4-6.6 第6章思维导图 第7章 输入输出系统7.1-7.2 第7章思维导图 抖动、请求分段存储管理方式、I/0系统的功能模型接口、I/O设备控制器、 第6章作业，课后13，15，18 10 第7章 输入输出系统7.3-7.7 第7章思维导图 中断和中断处理程序、设备驱动程序、与设备无关的I/O软件、用户层的I/O软件、缓冲区管理 11 习题讲解、期中测试 作业讲解、测试 12 第7章 输入输出系统7.8 第8章文件管理8.1和8.2 第8章思维导图 磁盘调度、文件和文件系统、文件的逻辑结构 13 第8章文件管理8.1和8.2 第8章思维导图 文件目录、文件共享、文件保护 作业13，14 14 第9章磁盘存储器管理 9.1和9.2 第9章思维导图 外存的组织方式、文件存储空间管理 作业15，16 15 第9章磁盘存储器管理 9.3-9.6 第9章思维导图 磁盘速度、可靠性、一致性等新技术 16 复习课、习题课 练习：配套练习题库 ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1703587640,"objectID":"edc547f69c006f435c6c53062358bb59","permalink":"https://fanfanshen.github.io/courses/operatingsystem/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/operatingsystem/","section":"courses","summary":"操作系统是计算机系统的指挥中心，它既是系统中各种资源的管理者，又是服务的提供者。操作系统在计算机系统中所处的地位和作用决定本课程在计算机学科课程中特殊重要的核心位置。","tags":null,"title":"《计算机操作系统》课程","type":"book"},{"authors":null,"categories":null,"content":"前沿说明 ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1714301630,"objectID":"54b67c87f7942353f60892cd023594ac","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter2/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter2/","section":"courses","summary":"Blah, blah, blah...","tags":null,"title":"第2章 CRUD操作","type":"book"},{"authors":null,"categories":null,"content":"1.重点 掌握索引的创建和优化方法 掌握单字段索引、复合索引、多键索引、索引管理、查询优化 2.索引的概念 索引是对数据库表中一列或多列的值进行排序的一种结构\n索引通常能够极大的提高查询的效率\n索引的建立要花费系统时间，索引文件也会占用磁盘空间 比如：书的目录、序号、学号等\nMongoDB索引的数据结构是B+树\n","date":1712534400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1714301630,"objectID":"b7d3381980b12a244289051f97fca388","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter3/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter3/","section":"courses","summary":"Blah, blah, blah...","tags":null,"title":"第3章 索引","type":"book"},{"authors":null,"categories":null,"content":"前沿说明 ","date":1712620800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1714296686,"objectID":"a17648fe5609d028bd35e6d43e065acb","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter4/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter4/","section":"courses","summary":"Blah, blah, blah...","tags":null,"title":"第4章 聚集操作","type":"book"},{"authors":null,"categories":null,"content":"","date":1712620800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1715209038,"objectID":"8f3dfb129cd0405f0111afd0ff74b8cc","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/","publishdate":"2024-04-09T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/","section":"courses","summary":"Blah, blah, blah...","tags":null,"title":"第5章 WiredTiger存储引擎","type":"book"},{"authors":null,"categories":null,"content":" 6.1 复制集概述 6.2 完整部署一个复制集 6.3 复制集工作机制 知识点\n理解复制集的概念和部署方法 掌握复制集的工作机制 数据同步 故障转移 写关注 读参考 ","date":1713571200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1714296686,"objectID":"807be8553c73259d5f8987540df3eb2d","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter6/","publishdate":"2024-04-20T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter6/","section":"courses","summary":"Blah, blah, blah...","tags":null,"title":"第6章 复制集","type":"book"},{"authors":null,"categories":null,"content":"实验大作业目标 训练系统开发应用能力和自行解决实际问题的能力。\n选题方向 实现特定功能的系统，其中大数据获取来源，包括交通、医疗、金融、知乎、微博、新闻、电影、影评、音乐、社交网络、物联网、图像、视频等。拟定的报告内容涉及的技术背景可以从上述领域中选取，或者选取自己熟悉的领域皆可。\n材料提交要求 1.排版要求：内容宋体、小四，格式统一，排版清晰漂亮 2.电子文档内容参考软件著作权的书写方法（见模版），文档命名规则：学号-姓名.docx 3.源代码文件夹命名“学号-姓名-源代码” 4.文档和源码文件夹一起打包，打包后的格式：学号-姓名.zip 5.打包的压缩包【学号-姓名.zip】发送给班长，纸质版文档第17周上课时，提交给班长。\n6.分享在阿里云部署后的演示链接，链接填入这里：实验大作业演示链接\n实验方案 1.领取阿里云云工开物，优惠卷300元 2.技术方案 方案1：本地获取数据，存入MongoDB，然后导出数据，数据上传至：文件存储NAS+云服务器ECS，在云服务器上展示自己的应用程序； 方案2：本地获取数据，存入MongoDB，然后导出数据，数据上传至：文件存储NAS+云服务器ECS+函数计算FC，通过函数计算FC设计自己的应用； 3.免费领取文件存储NAS，50GB，3个月 4.免费领取云服务器ECS，200元，3个月，注意：按使用量计算，超出收费 5.免费领取函数计算FC，180元，3个月，注意：按使用量计算，超出收费 6.300元优惠卷可以根据使用情况进行使用 7.使用方法参考链接： https://university.aliyun.com/activity/wintervacation 同济子豪兄：https://www.bilibili.com/video/BV1DZ421B7J9 老麦的工具库：https://www.bilibili.com/video/BV1Np421f7HE/ https://developer.aliyun.com/topic/freetier/nas 8.实验示例： 示例1：python爬取审计署新闻数据或者爬取指定内容，将爬取的数据写入mongodb，导出数据存入文件存储NAS，在云服务器ECS端，通过python GUI实现可视化的数据增、删、查、改功能。其他可视化和数据分析功能根据爱好添加。 示例2：python爬取互联网图片，写入mongodb，然后导出图像数据，存入文件存储NAS，通过函数计算FC对图片进行处理，有丰富的API，生成各式各样的图片进行展示。 9.还可以体验阿里云提供的其他服务，有兴趣的可以探索 特别提醒：文件存储NAS+云服务器ECS+函数计算FC，各种服务器使用完后，记得关闭!记得关闭!记得关闭! 可能按时间，或者按流量进行计算收费！！！！！！！\n得分要点 1.独立完成报告内容，严禁抄袭，如若相互抄袭，抄袭者和被抄袭者都是低分。 2.完成如下基本功能模块，包含导入大量数据、修改数据、删除数据、查询数据等。也可增加其他功能。但至少要有4个功能模块。\n3.报告内容需涵盖所学内容的80%以上。\n4.开发的系统有创新性，融入自己的idea，高分，90-100之间。\n5.开发的系统转化为申请软件著作权，可指导完成申请，高分，90-100之间。\n6.完成预定的功能，系统增删改查基本能用，中分，80-90之间。\n7.只完成部分或未实现等，低分，70-80之间。\n","date":1714262400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714301220,"objectID":"18aac05170b32912cc1a10ad2b6cc5a9","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/task/exp/","publishdate":"2024-04-28T00:00:00Z","relpermalink":"/courses/bigdatastorage/task/exp/","section":"courses","summary":"Blah, blah, blah...","tags":null,"title":"实验大作业","type":"book"},{"authors":[],"categories":null,"content":" 查看资源 一、在线数据库检索资源 DBLP sci-hub 谷歌学术 百度学术 中国知网 二、学术刊物 中国计算机学会推荐国际学术会议和期刊目录 CCF发布计算领域高质量科技期刊分级目录 计算机学报 中国科学(F) 软件学报 电子学报 自动化学报 计算机研究与发展 三、顶级会议/期刊 FAST、USENIX ATC、PPOPP、MSST、MASCOTS、SYSTOR、TOS、TC、TPDS、VLDB 偏系统：HPCA、ISCA、SOSP、OSDI、NSDI 偏数据库：SIGMOD、ICDE、PVLDB、VLDBJ 偏EDA：DAC、DATE、ICCD、ICCAD、ESWEEK 人工智能：AAAI，CVPR，ICCV，ICML，IJCAI，TPAMI 有源代码的会议（见论文右上角的图标Artifact Evaluation）：FAST、USENIX ATC、SOSP、OSDI、HPCA、PPOPP\n四、学者网站和学术资源 学者网站： song han, MIT, site: hanlab 学术资源： Rutgers Efficient AI (REFAI) Seminar, https://sites.google.com/site/boyuaneecs/efficient-ai-seminar-talk?authuser=0 五、科研方法 ","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712642331,"objectID":"0d9ca5542a442d81abaed094383e30a0","permalink":"https://fanfanshen.github.io/library/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/library/","section":"","summary":"查看资源 一、在线数据库检索资源 DBLP sci-hub 谷歌学术 百度学术 中国知网 二、学术刊物 中国计算机学会推荐国际学术会议和期刊目录 CCF发布计算领域高质量科技期刊分级目录 计算机学报 中国科学(F) 软件学报 电子学报 自动化学报 计算机研究与发展 三、顶级会议/期刊 FAST、USENIX ATC、PPOPP、MSST、MASCOTS、SYSTOR、TOS、TC、TPDS、VLDB 偏系统：HPCA、ISCA、SOSP、OSDI、NSDI 偏数据库：SIGMOD、ICDE、PVLDB、VLDBJ 偏EDA：DAC、DATE、ICCD、ICCAD、ESWEEK 人工智能：AAAI，CVPR，ICCV，ICML，IJCAI，TPAMI 有源代码的会议（见论文右上角的图标Artifact Evaluation）：FAST、USENIX ATC、SOSP、OSDI、HPCA、PPOPP\n四、学者网站和学术资源 学者网站： song han, MIT, site: hanlab 学术资源： Rutgers Efficient AI (REFAI) Seminar, https://sites.","tags":[],"title":"学术资源","type":"page"},{"authors":null,"categories":null,"content":" 欢迎研究生、本科生加入我们，一起学习，共同进步！联系邮箱：ffshen@nau.edu.cn 一、指导学生情况 2024，研究生：惠丽洁，Dynamic Grouping Scheme for Personalized Federated Meta-Learning，投稿中 2024年4月，研究生：杨博帆获得2024年江苏省研究生实践创新计划项目，立项，资助1.5万元 2024年4月，研究生：史林，BMSE: Blockchain-based multi-keyword searchable encryption for electronic medical records，Computer Standards \u0026amp; Interfaces(中科院2区) 2023年7月，研究生：汤星译，基于iFA-LSTM的恶意行为检测方法，计算机工程与科学（北大核心录用），2024.1 2023年6月，研究生：汤星译获得2023年江苏省研究生实践创新计划项目，立项，资助1.5万元 2023年6月，研究生：刘海鹏获得2023年江苏省研究生实践创新计划项目，立项，资助1.5万元 2023年3月，研究生：刘海鹏，基于AHP的多特征融合图像质量评价算法，计算机仿真（北大核心录用），appear in 2024 2023年4月，研究生：杨博帆，基于深度强化学习的无人机矿井自主巡航研究，武汉大学学报（北大核心），2023.4(优秀论文) 2022年6月，本科生：夏锐禹，校优秀本科生毕业设计，目前为北京工业大学硕士生 2022年3月，研究生：史林，2022年度江苏省研究生科研与实践创新计划项目，立项，1.5万元 2023年，指导学生获得大学生创新创业训练计划项目，国家级，袁媛，颜敏杰，陶琴 2023年，指导学生获得中国大学生服务外包创新创业大赛，省级三等奖2项 2023年，指导学生获得蓝桥杯省二等奖 2021年7月，指导学生获得中国大学生计算机设计大赛（14届），国家级，二等奖，学生：左量、吴子怡、许傲 2021年5月，指导学生获得中国大学生计算机设计大赛，江苏省级，三等奖，学生：左量、吴子怡、许傲 二、在读研究生 2023级：苏文璋，李倩倩 2022级：杨博帆，梁琦玮，惠丽洁 2021级：史林，刘海鹏，汤星译 三、指导的本科生(毕业生) 2024届：缪浩然（无锡海隆），秦子恒（中科创达），唐一宸（雄安联通），汤觉淇（江苏海隆软件）， 2023届：常旭（南京公务员），周瑾（SHEIN），叶国绪（简睿捷软件），曹晨洋，陈一祺，索朗扎巴，陈燚（西南大学读研），陈健（南审读研），任翔宇（南审读研），杨聪（东华大学读研） 2022届：叶风云（南京毕马威服务中心，优秀毕业论文），刘宇（风云再起），沈金泽（中国科学技术大学读研），张晓宇（博泰车联网），夏锐禹（北京工业大学读研，优秀毕业论文），唐钦（东北大学读研），章江林(南京国睿信维) 2021届：刘浩，陈霖 ","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712632575,"objectID":"cee200f3791b5f710de997cf3f1356b0","permalink":"https://fanfanshen.github.io/students/member/","publishdate":"2030-06-01T13:00:00Z","relpermalink":"/students/member/","section":"students","summary":"历年指导的研究生、本科生成果情况，毕业情况等。","tags":null,"title":"学生情况","type":"students"},{"authors":null,"categories":null,"content":"MongoDB中概念对比 2.1-1 MongoDB中基本命令 启动数据库命令 mongod:启动服务器\nmongo.exe:启动客户端\n6.0以后版本输入mongosh即可同时开启\n数据库操作命令 use DATABASE //如果数据库不存在，则创建数据库，否则切换到指定数据库。\nshow dbs // 命令可以显示所有数据的列表。\ndb // 命令可以显示当前数据库对象或集合。\nuse runoob\nshow dbs // 未显示runoob,插入数据runoob才显示\ndb.runoob.insert({“name”:“helloword\u0026#34;})\ndb.dropDatabase() //删除当前使用的数据库\n数据库创建集合命令 db.createCollection(“customers”) //创建集合\n数据库删除集合命令 db.collection.drop() //将collection替换为某个待删除的集合\n数据库插入操作命令 语法：db.COLLECTION_NAME.insert(document)\n注意点：\n1、第一次插入数据时，不需要预先创建COLLECTION_NAME，插入数据时，会自动创建\n2、每次插入数据若没显示指定字段“_id”，则会默认创建一个主键“_id”，为ObjectId类型，好处是支持分布式存储。 3、在MongoDB中，每一个集合都必须有一个“_id”字段，不管是自动生成还是指定的，值必须唯一；\n4、如果插入重复值将会抛出异常\n###直接插入 db.users.insert({title: ‘MongoDB’, tags: ‘good’})\ndb.users.find() //查看文档 ###将数据定义为一个document变量 document= ({title: ‘MongoDB’, tags: ‘good’}) db.users.insert(document) ###其他语法 db.collection.insertOne():向指定集合中插入一条文档数据\ndb.collection.insertMany([{d1},{d2}…]):向指定集合中插入多条文档数据，参数为数组\n","date":1712966400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296557,"objectID":"efb3d5b8fb4ef7d42b098b08d51106c9","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter2/2.1/","publishdate":"2024-04-13T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter2/2.1/","section":"courses","summary":"MongoDB中概念对比 2.1-1 MongoDB中基本命令 启动数据库命令 mongod:启动服务器\nmongo.exe:启动客户端\n6.0以后版本输入mongosh即可同时开启\n数据库操作命令 use DATABASE //如果数据库不存在，则创建数据库，否则切换到指定数据库。\nshow dbs // 命令可以显示所有数据的列表。\ndb // 命令可以显示当前数据库对象或集合。\nuse runoob\nshow dbs // 未显示runoob,插入数据runoob才显示\ndb.runoob.insert({“name”:“helloword\"})\ndb.dropDatabase() //删除当前使用的数据库\n数据库创建集合命令 db.createCollection(“customers”) //创建集合","tags":null,"title":"2.1 插入操作","type":"book"},{"authors":null,"categories":null,"content":"MongoDB中基本命令 数据库删除操作 deleteOne：从集合中删除一条文档记录\ndeleteMany:批量删除集合中的文档记录\n语法 2.2-1 语法解释 2.2-2 ","date":1712966400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"306c71cff5cbe65fb148d3551ca5b0b0","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter2/2.2/","publishdate":"2024-04-13T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter2/2.2/","section":"courses","summary":"MongoDB中基本命令 数据库删除操作 deleteOne：从集合中删除一条文档记录\ndeleteMany:批量删除集合中的文档记录\n语法 2.2-1 语法解释 2.2-2 ","tags":null,"title":"2.2 删除操作","type":"book"},{"authors":null,"categories":null,"content":"MongoDB中基本命令 数据库更新操作 updateOne:修改单条文档记录，即使查询多条也只更新第一条\nupdateMany：修改所有匹配的文档记录\n语法 2.3-1 语法解释 2.3-2 数据库更新操作 replaceOne: 将文档记录替换为一条新文档记录\nupdate：相当于前三条的集合，取决于第二个参数\n语法 2.3-3 语法解释 2.3-4 数据库常用修改操作符 $unset表示删除集合字段；\n$rename将name重命名；$currentDate将字段的值修改为当前的时间；\n$mul将字段的值乘以一个数字；\n$min保留修改值和原值中最小的值；\n$max保留修改值和原值中最大的值；\n","date":1712966400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"6e9decbc37464ec902cf4a2adfaf2c96","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter2/2.3/","publishdate":"2024-04-13T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter2/2.3/","section":"courses","summary":"MongoDB中基本命令 数据库更新操作 updateOne:修改单条文档记录，即使查询多条也只更新第一条\nupdateMany：修改所有匹配的文档记录\n语法 2.3-1 语法解释 2.3-2 数据库更新操作 replaceOne: 将文档记录替换为一条新文档记录\nupdate：相当于前三条的集合，取决于第二个参数\n语法 2.3-3 语法解释 2.3-4 数据库常用修改操作符 $unset表示删除集合字段；\n$rename将name重命名；$currentDate将字段的值修改为当前的时间；\n$mul将字段的值乘以一个数字；\n$min保留修改值和原值中最小的值；\n$max保留修改值和原值中最大的值；","tags":null,"title":"2.3 修改操作","type":"book"},{"authors":null,"categories":null,"content":"MongoDB中基本命令 数据库查询操作 查询操作（ find() ）:BSON结构数据\n语法 2.4-1 语法解释 2.4-2 SQL与MongoDB 2.4-3 条件语法\n1.查询文档find()，$and条件语法：\n对于单键：db.col.find({likes : {$lt :200, $gt : 100}})\n可以传入多个键(key)，每个键(key)以逗号隔开\ndb.col.find({key1:value1, key2:value2}).pretty() db.collection.find({$and:[{key1:value1},{key2:value2}]}).pretty()\n2.查询文档find()，$or条件语法：\ndb.collection.find({$or:[{key1:value1},{key2:value2}]}).pretty()\n3.查询文档find()，$not条件语法，非运算：\n4.查询文档find()，$exists: 是否包含某个字段\n{field:{$exists:}}，true返回包含field字段的文档记录，false返回不包含该字段的记录 5.查询文档find()，$text: 文本查询\n返回匹配文本的记录\n6.查询文档find()，$regex: 正则表达式\n7.查询文档find()，嵌套文档查询，orders.item\n8.查询文档find()，支持地理位置查询\n数组操作\n1.精确匹配数组值\n2.匹配数组中的一个元素值\n3.匹配指定位置的元素值\n4.指定数组索引并匹配嵌套文档中的字段值\n2.4-4 2.4-5 查询投射\n返回匹配文档的指定字段；\n好处：减少返回数据到客户端的网络流量 查询示例\n2.4-6 ","date":1712966400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"75f04924c45479e1738a17a6b0a777c1","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter2/2.4/","publishdate":"2024-04-13T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter2/2.4/","section":"courses","summary":"MongoDB中基本命令 数据库查询操作 查询操作（ find() ）:BSON结构数据\n语法 2.4-1 语法解释 2.4-2 SQL与MongoDB 2.4-3 条件语法\n1.查询文档find()，$and条件语法：\n对于单键：db.col.find({likes : {$lt :200, $gt : 100}})\n可以传入多个键(key)，每个键(key)以逗号隔开\ndb.col.find({key1:value1, key2:value2}).pretty() db.collection.find({$and:[{key1:value1},{key2:value2}]}).pretty()\n2.查询文档find()，$or条件语法：\ndb.collection.find({$or:[{key1:value1},{key2:value2}]}).pretty()\n3.查询文档find()，$not条件语法，非运算：\n4.查询文档find()，$exists: 是否包含某个字段\n{field:{$exists:}}，true返回包含field字段的文档记录，false返回不包含该字段的记录 5.","tags":null,"title":"2.4 查询操作","type":"book"},{"authors":null,"categories":null,"content":"MongoDB中基本命令 数据库批量写操作 解释\nMongoDB支持将插入操作、修改操作、删除操作放在一个bulkwrite之中。执行批量写操作。即多种操作同时进行。\n语法 语法格式如下：orderd是否按顺序执行 2.1-1 ","date":1712966400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"1abab4be397316f9471078330fd65cbf","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter2/2.5/","publishdate":"2024-04-13T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter2/2.5/","section":"courses","summary":"MongoDB中基本命令 数据库批量写操作 解释\nMongoDB支持将插入操作、修改操作、删除操作放在一个bulkwrite之中。执行批量写操作。即多种操作同时进行。\n语法 语法格式如下：orderd是否按顺序执行 2.1-1 ","tags":null,"title":"2.4 查询操作","type":"book"},{"authors":null,"categories":null,"content":"索引的创建方法 语法格式： db.**collection.** createIndex(keys, options)- Key值为你要创建的索引字段，1为按升序创建索引，如果你想按降序来创建索引指定为-1即可 3.0.0版本前创建索引方法为 db.collection.ensureIndex()，之后的版本使用了 db.collection.createIndex() 方法，ensureIndex() 还能用，但只是 createIndex() 的别名。\n例如：db.col.createIndex({“title”:1}) 查询创建的索引： db.customers.getIndexes()\ncreateIndex()可选参数参考表 可选参数参考表 ","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712630632,"objectID":"426579b2c46f0f1c95ce932922be1362","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter3/3.1/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter3/3.1/","section":"courses","summary":"索引的创建方法 语法格式： db.**collection.** createIndex(keys, options)- Key值为你要创建的索引字段，1为按升序创建索引，如果你想按降序来创建索引指定为-1即可 3.0.0版本前创建索引方法为 db.collection.ensureIndex()，之后的版本使用了 db.collection.createIndex() 方法，ensureIndex() 还能用，但只是 createIndex() 的别名。\n例如：db.col.createIndex({“title”:1}) 查询创建的索引： db.customers.getIndexes()\ncreateIndex()可选参数参考表 可选参数参考表 ","tags":null,"title":"3.1 创建索引","type":"book"},{"authors":null,"categories":null,"content":"3.2.1 索引的删除方法 语法格式如下： db.collection.dropIndex(“索引名称”) //删除集合指定索引 示例：db.user.dropIndex({id:1})\ndb.col.dropIndexes() //删除集合所有索引 获取更多命令，可以输入db.collection.后双击Tab键。 ","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712630649,"objectID":"9e6cabd52c5bf88de9789d5720359931","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter3/3.2/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter3/3.2/","section":"courses","summary":"3.2.1 索引的删除方法 语法格式如下： db.collection.dropIndex(“索引名称”) //删除集合指定索引 示例：db.user.dropIndex({id:1})\ndb.col.dropIndexes() //删除集合所有索引 获取更多命令，可以输入db.collection.后双击Tab键。 ","tags":null,"title":"3.2 删除索引","type":"book"},{"authors":null,"categories":null,"content":"3.3.1 了解单字段索引 MongoDB默认为所有集合都创建了一个 _id字段的单字段索引，而且这个索引是唯一的，不能删除 ； _id字段作为一个集合的主键，值是唯一的； 对于一个集合来说，也可以在其他字段上创建单字段的唯一索引； 3.3.2 创建单字段索引准备工作 准备测试数据:\nfor(var i=1;i\u0026lt;10;i++) db.customers.insert({name:\u0026#34;jordan\u0026#34;+i,country:\u0026#34;American\u0026#34;}) for(var i=1;i\u0026lt;10;i++) db.customers.insert({name:\u0026#34;gaga\u0026#34;+i,country:\u0026#34;American\u0026#34;}) for(var i=1;i\u0026lt;10;i++) db.customers.insert({name:\u0026#34;ham\u0026#34;+i,country:\u0026#34;UK\u0026#34;}) for(var i=1;i\u0026lt;10;i++) db.customers.insert({name:\u0026#34;brown\u0026#34;+i,country:\u0026#34;UK\u0026#34;}) for(var i=1; i\u0026lt;10; i++) db.customers.insert({name:\u0026#34;ramda\u0026#34;+i, country:\u0026#34;Malaysia\u0026#34;}) 注：删除上一章添加的customers数据\n3.3.3 创建单字段唯一索引 db.customers.createIndex({name:1},{unique:true})\n索引创建成功后可通过如下语句查询增加的索引： db.customers.getIndexes()\nv表示索引的版本； key表示索引建立在哪个字段上； 1表示索引按照升序排列； ns索引所在的命名空间\n效果如图\n显示单字段索引 索引查询效率分析 db.customers.find({name:\u0026#34;ramda9\u0026#34;}).explain(\u0026#34;executionStats\u0026#34;) //使用索引字段作为查询选择器 db.customers.find({country:\u0026#34;Malaysia\u0026#34;}).explain(\u0026#34;executionStats\u0026#34;) //不使用索引字段作为查询选择器\n使用索引：\n使用索引 不使用索引：\n不使用索引 totalKeysExamined：遍历索引的次数 totalDocsExamined：遍历文档的次数 executionTimeMillis：预测需要执行的时间\n","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712630671,"objectID":"03d1c1e8643be095e1b153b61fa66ea8","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter3/3.3/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter3/3.3/","section":"courses","summary":"3.3.1 了解单字段索引 MongoDB默认为所有集合都创建了一个 _id字段的单字段索引，而且这个索引是唯一的，不能删除 ； _id字段作为一个集合的主键，值是唯一的； 对于一个集合来说，也可以在其他字段上创建单字段的唯一索引； 3.3.2 创建单字段索引准备工作 准备测试数据:\nfor(var i=1;i\u003c10;i++) db.customers.insert({name:\"jordan\"+i,country:\"American\"}) for(var i=1;i\u003c10;i++) db.customers.insert({name:\"gaga\"+i,country:\"American\"}) for(var i=1;i\u003c10;i++) db.customers.insert({name:\"ham\"+i,country:\"UK\"}) for(var i=1;i\u003c10;i++) db.customers.insert({name:\"brown\"+i,country:\"UK\"}) for(var i=1; i\u003c10; i++) db.customers.insert({name:\"ramda\"+i, country:\"Malaysia\"}) 注：删除上一章添加的customers数据\n3.3.3 创建单字段唯一索引 db.","tags":null,"title":"3.3 单字段索引","type":"book"},{"authors":null,"categories":null,"content":" MongoDB支持多个字段的复合索引，复合索引支持匹配多个字段的查询。 for(var i=1; i\u0026lt;10; i++) db.customers.insert({name:\u0026#34;lanbo\u0026#34;+i, country:\u0026#34;Malaysia\u0026#34;}) //增加测试数据 db.customers.find({country:\u0026#34;Malaysia\u0026#34;}).explain(\u0026#34;executionStats\u0026#34;) //执行查询语句 此查询会扫描54个文档，全表扫描，匹配上的文档只有18个，没有用索引； db.customers.createIndex({country:1}) //增加索引 再执行查询语句可知，此查询会扫描18个文档，同时匹配18个； db.customers.createIndex({name:1,country:1}) //创建复合索引 db.customers.find({name:\u0026#34;lanbo2\u0026#34;,country:\u0026#34;Malaysia\u0026#34;}).explain(\u0026#34;executionStats\u0026#34;) //扫描文档1次即匹配 ","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712630683,"objectID":"44271ca707f556e0a5b1a5ea616323a9","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter3/3.4/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter3/3.4/","section":"courses","summary":" MongoDB支持多个字段的复合索引，复合索引支持匹配多个字段的查询。 for(var i=1; i\u003c10; i++) db.customers.insert({name:\"lanbo\"+i, country:\"Malaysia\"}) //增加测试数据 db.customers.find({country:\"Malaysia\"}).explain(\"executionStats\") //执行查询语句 此查询会扫描54个文档，全表扫描，匹配上的文档只有18个，没有用索引； db.customers.createIndex({country:1}) //增加索引 再执行查询语句可知，此查询会扫描18个文档，同时匹配18个； db.customers.createIndex({name:1,country:1}) //创建复合索引 db.customers.find({name:\"lanbo2\",country:\"Malaysia\"}).explain(\"executionStats\") //扫描文档1次即匹配 ","tags":null,"title":"3.4 复合索引","type":"book"},{"authors":null,"categories":null,"content":"3.5.1 数组的多键索引在B-Tree叶子节点上的排列样式 排列样式 3.5.2 嵌套文档多键索引 如果数组的元素值为一个嵌套文档，结构如下 嵌套文档 可以创建{StatusInfo.desc:1}的多键索引 db.Order.ensureIndex({StatusInfo.desc:1}) 创建图示 数组多键索引 ","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712630704,"objectID":"4b547cb52a907f927777bef77add77b6","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter3/3.5/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter3/3.5/","section":"courses","summary":"3.5.1 数组的多键索引在B-Tree叶子节点上的排列样式 排列样式 3.5.2 嵌套文档多键索引 如果数组的元素值为一个嵌套文档，结构如下 嵌套文档 可以创建{StatusInfo.desc:1}的多键索引 db.Order.ensureIndex({StatusInfo.desc:1}) 创建图示 数组多键索引 ","tags":null,"title":"3.5 数组的多键索引","type":"book"},{"authors":null,"categories":null,"content":" 全文索引，在字符串或字符串数组上 db.profiles.createIndex({comments:\u0026#34;text\u0026#34;})\n地理位置索引 db.address.createIndex({\u0026#34;location\u0026#34;:\u0026#34;2dsphere\u0026#34;})//球面空间 db.address.createIndex({\u0026#34;location\u0026#34;:\u0026#34;2d\u0026#34;})//平面空间\nHash索引 db.address.createIndex({_id:\u0026#34;hashed\u0026#34;}) //利用hash函数计算字段的值\nTTL索引 db.log_event.createIndex({date:1},{expireAfterSeconds:600}) //10分钟后自动删除\n","date":1712534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712630719,"objectID":"c280a4f6bf94466725e323c169e060c0","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter3/3.6/","publishdate":"2024-04-08T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter3/3.6/","section":"courses","summary":"全文索引，在字符串或字符串数组上 db.profiles.createIndex({comments:\"text\"})\n地理位置索引 db.address.createIndex({\"location\":\"2dsphere\"})//球面空间 db.address.createIndex({\"location\":\"2d\"})//平面空间\nHash索引 db.address.createIndex({_id:\"hashed\"}) //利用hash函数计算字段的值\nTTL索引 db.log_event.createIndex({date:1},{expireAfterSeconds:600}) //10分钟后自动删除","tags":null,"title":"3.6 其他索引","type":"book"},{"authors":["沈凡凡"],"categories":null,"content":"致谢 | 2023年度《武汉大学学报（理学版）》 “突出贡献奖”“优秀青年编委”“优秀审稿人”“优秀论文”名单\n","date":1705968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706258425,"objectID":"df146b2bbbe91176be3b8fc7125f3f36","permalink":"https://fanfanshen.github.io/news/2024-reward-bestpaper/","publishdate":"2024-01-23T00:00:00Z","relpermalink":"/news/2024-reward-bestpaper/","section":"news","summary":"致谢 | 2023年度《武汉大学学报（理学版）》 “突出贡献奖”“优秀青年编委”“优秀审稿人”“优秀论文”名单","tags":null,"title":"Our paper was awarded the best paper of 2023 in 《武汉大学学报（理学版）》. Congratulations to Bofan Yang.","type":"news"},{"authors":["沈凡凡"],"categories":null,"content":"","date":1705449600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706279011,"objectID":"50a5afbfd5cb97b25350d7eaa32fed37","permalink":"https://fanfanshen.github.io/news/2023-paper-ifalstm/","publishdate":"2024-01-17T00:00:00Z","relpermalink":"/news/2023-paper-ifalstm/","section":"news","summary":"","tags":null,"title":"Our paper \"基于iFA-LSTM的恶意行为检测方法\" is accepted by 计算机工程与科学(CCF-T2). Congratulations to Xingyi Tang.","type":"news"},{"authors":["沈凡凡"],"categories":null,"content":"恭喜课题组成员(史林)的论文被Computer Standards \u0026amp; Interfaces（中科院二区）期刊接收。\nTitle：BMSE: Blockchain-based multi-keyword searchable encryption for electronic medical records\n","date":1702512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702541468,"objectID":"7721eab169de4a3998e0ed954a26376e","permalink":"https://fanfanshen.github.io/news/2023-paper-csi/","publishdate":"2023-12-14T00:00:00Z","relpermalink":"/news/2023-paper-csi/","section":"news","summary":"恭喜课题组成员(史林)的论文被Computer Standards \u0026 Interfaces（中科院二区）期刊接收。\nTitle：BMSE: Blockchain-based multi-keyword searchable encryption for electronic medical records","tags":null,"title":"Our paper \"BMSE:Blockchain-based multi-keyword searchable encryption for electronic medical records\" is accepted by Computer Standards \u0026 Interfaces (中科院2区)","type":"news"},{"authors":["沈凡凡"],"categories":null,"content":"2023年11月2日应邀参加阿里云栖大会并做报告\n","date":1698883200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706258425,"objectID":"686ef29a4b268fd9ea2f4074e5dd2e4e","permalink":"https://fanfanshen.github.io/news/2023-conf-aliyun/","publishdate":"2023-11-02T00:00:00Z","relpermalink":"/news/2023-conf-aliyun/","section":"news","summary":"2023年11月2日应邀参加阿里云栖大会并做报告","tags":null,"title":"应邀参加阿里云栖大会并做报告","type":"news"},{"authors":null,"categories":null,"content":"","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"724b20c3d126509d0ed7da9c4c93504c","permalink":"https://fanfanshen.github.io/project/22bigdata/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/project/22bigdata/","section":"project","summary":"主题：审计大数据高性能高可靠存储与计算技术","tags":["Research"],"title":"主持、江苏省高等学校自然科学研究重大项目(22KJA520004)，2022.7-2025.8","type":"project"},{"authors":["Fanfan Shen*","Chao Xu","Jun Zhang","Yong Chen","Yanxiang He"],"categories":[],"content":"","date":1638957643,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"8156a4a1e50ba774ea02dee98ff01018","permalink":"https://fanfanshen.github.io/publication/2021rldc/","publishdate":"2023-10-08T18:00:43+08:00","relpermalink":"/publication/2021rldc/","section":"publication","summary":"","tags":[],"title":"Reinforcement Learning based Data Compression for Energy-Efficient Non-volatile Caches","type":"publication"},{"authors":null,"categories":null,"content":"","date":1611619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"e3f39d0d0fd3e18ffb79bea71387a919","permalink":"https://fanfanshen.github.io/project/22teaching/","publishdate":"2021-01-26T00:00:00Z","relpermalink":"/project/22teaching/","section":"project","summary":"主题：混合式教学模式创新.","tags":["Teaching"],"title":"主持、江苏省教育科学“十四五”规划重点课题(C-b/2021/01/26)、2022.1-2023.12","type":"project"},{"authors":[],"categories":[],"content":" 主持、国家自然科学基金(61902189)、2020.1-2022.12，已结题\n主持、江苏省自然科学基金(BK20180821)、2018.7-2021.6，已结题\n主持、江苏省高等学校自然科学研究面上项目(18KJB520026)、2018.9-2020.8，已结题\n主持、江苏省教育科学“十三五”规划重点课题(C-a/2018/01/09)、2018.6-2020.6，已结题\n","date":1602206936,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"153d02c6f622514fd3e9bcfe5ebefb09","permalink":"https://fanfanshen.github.io/project/others/","publishdate":"2020-10-09T09:28:56+08:00","relpermalink":"/project/others/","section":"project","summary":"国家自科，省自科，高校面上等","tags":["Research"],"title":"2022年以前的结题项目","type":"project"},{"authors":["Fanfan Shen","Chao Xu and Jun Zhang"],"categories":[],"content":"","date":1581156710,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"4b499d400c814cba481afbc11e32bf5e","permalink":"https://fanfanshen.github.io/publication/2020access/","publishdate":"2023-10-08T18:11:50+08:00","relpermalink":"/publication/2020access/","section":"publication","summary":"","tags":[],"title":"Statistical Behavior Guided Block Allocation in Hybrid Cache Based Edge Computing for Cyber-Physical-Social Systems","type":"publication"},{"authors":["Fanfan Shen*","Yanxiang He","Jun Zhang","Qingan Li","Jianhua Li","Chao Xu"],"categories":[],"content":"","date":1570529944,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"ae62b47c9ae4b63f649d31607d3d9e69","permalink":"https://fanfanshen.github.io/publication/2019cee/","publishdate":"2023-10-08T18:19:04+08:00","relpermalink":"/publication/2019cee/","section":"publication","summary":"","tags":[],"title":"Reuse Locality aware Cache Partitioning for Last-Level Cache","type":"publication"},{"authors":["Fanfan Shen","Yanxiang He","Jun Zhang","Chao Xu"],"categories":[],"content":"","date":1570529855,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"5a28ad14720c1067f0fd37002003db63","permalink":"https://fanfanshen.github.io/publication/2019js/","publishdate":"2023-10-08T18:17:35+08:00","relpermalink":"/publication/2019js/","section":"publication","summary":"","tags":[],"title":"Periodic Learning based Region Selection for Energy Efficient MLC STT-RAM Cache","type":"publication"},{"authors":null,"categories":null,"content":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you’ll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python import pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;} - Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal ``` renders as\n- Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap - Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ ``` renders as\n- Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ ### Charts Wowchemy supports the popular [Plotly](https://plot.ly/) format for interactive charts. Save your Plotly JSON in your page folder, for example `line-chart.json`, and then add the `{{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}}` shortcode where you would like the chart to appear. Demo: You might also find the [Plotly JSON Editor](http://plotly-json-editor.getforge.io/) useful. ### Math Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the `math` option in your `config/_default/params.yaml` file. To render _inline_ or _block_ math, wrap your LaTeX math with `{{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}}` or `{{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}`, respectively. (We wrap the LaTeX math in the Wowchemy _math_ shortcode to prevent Hugo rendering our math as Markdown. The _math_ shortcode is new in v5.5-dev.) Example **math block**: ```latex {{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ Example inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$ f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases} $$ Diagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ``` renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ``` renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : …","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701916630,"objectID":"9ffdabb80e2a1e7ef0294aebd370da69","permalink":"https://fanfanshen.github.io/news/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/news/writing-technical-content/","section":"news","summary":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"news"},{"authors":null,"categories":null,"content":"MongoDB是一个可扩展、开源、表结构自由，用C++语言编写的面向文档的分布式文件存储的数据库，旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。\nMongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。\n1.1-1 数据库引擎综合排行榜：第5名数据来源：https://db-engines.com/en/ranking\n文档数据库排名第一：https://db-engines.com/en/ranking/document+store\n综合排行榜：第5名，数据来源：https://db-engines.com/en/ranking\n上述网站可查询最新数据\n1.1-2 MongoDB能支撑大数据系统\n实时的可操作的大数据存储系统 离线大数据分析系统 MongoDB天生为云计算而生\n可扩展架构，可以启用分片和水平扩展，提供云存储所需的技术； 自动管理被称为“副本集”的冗余服务器； MongoDB为多家领先的云计算供应商，如阿里巴巴，腾讯，360，百度\n1.1-3 关系数据库中最基本的单元是行，MongoDB中最基本的存储单元是document，如：\n1.1-4 用JSON格式类似的键值对来存储，值的类型有字符串、数字、日期等，也称BSON对象；\nMongoDB与关系数据库的重大区别是：可扩展的表结构，即collection中的document所拥有的字段是可以变化的\n1.1-5 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"c7b5996d96304845521cdc42a6b1dc71","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter1/1.1/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter1/1.1/","section":"courses","summary":"MongoDB是一个可扩展、开源、表结构自由，用C++语言编写的面向文档的分布式文件存储的数据库，旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。\nMongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。\n1.1-1 数据库引擎综合排行榜：第5名数据来源：https://db-engines.com/en/ranking\n文档数据库排名第一：https://db-engines.com/en/ranking/document+store\n综合排行榜：第5名，数据来源：https://db-engines.com/en/ranking\n上述网站可查询最新数据\n1.1-2 MongoDB能支撑大数据系统\n实时的可操作的大数据存储系统 离线大数据分析系统 MongoDB天生为云计算而生\n可扩展架构，可以启用分片和水平扩展，提供云存储所需的技术； 自动管理被称为“副本集”的冗余服务器； MongoDB为多家领先的云计算供应商，如阿里巴巴，腾讯，360，百度\n1.1-3 关系数据库中最基本的单元是行，MongoDB中最基本的存储单元是document，如：\n1.1-4 用JSON格式类似的键值对来存储，值的类型有字符串、数字、日期等，也称BSON对象；\nMongoDB与关系数据库的重大区别是：可扩展的表结构，即collection中的document所拥有的字段是可以变化的\n1.1-5 ","tags":null,"title":"1.1 MongoDB的发展与现状","type":"book"},{"authors":null,"categories":null,"content":" 1.2-1 根据 Gartner 调查，70%的 Hadoop大数据分析项目未能体现预期价值 随着业务的发展，实时数据处理场景变得越来越多，Hadoop这种更适合处理离线批量数据的技术变得不适应 因此需要引人新的NOSQL技术来应对这种场景，发挥大数据实时处理的优势 1.2-2 1.2-3 MongoDB可以替换HDFS,作为大数据平台中最核心的部分； 优势如下：\nHDFS以文件为单位，每个文件大小为64MB~128MB，MongoDB作为文档数据库则表现得更加细颗粒化 MongoDB支持HDFS所没有的索引概念，所以在读取速度上更快，MongoDB比HDFS 更加易于修改其写入后的数据。 HDFS 的响应级别为分钟，而MongoDB的响应级别为毫秒: 如果使用MongoDB数据库，就不用像传统模式那样，到Redis内存数据库计算后，再将其另存到HDFS上。 可以利用MongoDB强大的Aggregate功能进行数据筛选或预处理 1.2-4 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"d2e33e36f9f4e5671c5c0c27520db6ce","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter1/1.2/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter1/1.2/","section":"courses","summary":" 1.2-1 根据 Gartner 调查，70%的 Hadoop大数据分析项目未能体现预期价值 随着业务的发展，实时数据处理场景变得越来越多，Hadoop这种更适合处理离线批量数据的技术变得不适应 因此需要引人新的NOSQL技术来应对这种场景，发挥大数据实时处理的优势 1.2-2 1.2-3 MongoDB可以替换HDFS,作为大数据平台中最核心的部分； 优势如下：\nHDFS以文件为单位，每个文件大小为64MB~128MB，MongoDB作为文档数据库则表现得更加细颗粒化 MongoDB支持HDFS所没有的索引概念，所以在读取速度上更快，MongoDB比HDFS 更加易于修改其写入后的数据。 HDFS 的响应级别为分钟，而MongoDB的响应级别为毫秒: 如果使用MongoDB数据库，就不用像传统模式那样，到Redis内存数据库计算后，再将其另存到HDFS上。 可以利用MongoDB强大的Aggregate功能进行数据筛选或预处理 1.2-4 ","tags":null,"title":"1.2 MongoDB与Hadoop比较","type":"book"},{"authors":null,"categories":null,"content":" 关系数据库中常用的SQL在MongoDB中都有对应的解决方案，JOIN语句例外，不支持；\nMongoDB的特点：\n嵌套文档模型\n自由的表结构\n自带强大的计算框架，支持MapReduce、spark\n复制集保证数据高可靠性\n分片集群实现高可扩展性，实现海量数据的分布式存储\n多文档事务的支持，高并发能力\n","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"728b018713b0f52f4c9def055fce332d","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter1/1.3/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter1/1.3/","section":"courses","summary":"关系数据库中常用的SQL在MongoDB中都有对应的解决方案，JOIN语句例外，不支持；\nMongoDB的特点：\n嵌套文档模型\n自由的表结构\n自带强大的计算框架，支持MapReduce、spark\n复制集保证数据高可靠性\n分片集群实现高可扩展性，实现海量数据的分布式存储\n多文档事务的支持，高并发能力","tags":null,"title":"1.3 关键特性","type":"book"},{"authors":null,"categories":null,"content":"1.安装步骤\n下载地址：https://www.mongodb.com/download-center/community 版本4.4或更高版本；或者网盘下载：https://pan.baidu.com/s/15KwMqxcVFi8D6BpMBKNQkA?pwd=abt7 提取码: abt7 安装方法参考：https://www.runoob.com/mongodb/mongodb-window-install.html 安装过程中不要勾选MongoDB Compass（可视化环境），MongoDB单独安装。 2.配置数据和日志文件目录（自定义）\n创建数据目录：D:\\mongodb\\data\\db 创建日志目录：D:\\mongodb\\data\\log 创建日志文件：D:\\mongodb\\data\\log\\mongodb.log 3.安装成功与否测试\n启动服务器：\nC:\\Program Files\\MongoDB\\Server\\4.4\\bin\u0026gt;.\\mongod.exe --dbpath d:\\mongodb\\data\\db 看到日志倒数第二行：waiting for connections on port 27017\n浏览器输入：http://localhost:27017/\n1.4-1 出现上述情况，说明安装正常 4.MongoDB的后台管理shell（mongo进程）\nMongoDB Shell是MongoDB自带的交互式Javascript shell,用来对MongoDB进行操作和管理的交互式环境。\n进入安装目录bin下，运行mongo进程：\n`C:\\Program Files\\MongoDB\\Server\\4.4\\bin\u0026gt;.\\mongo.exe --port 27017` 默认连接到test数据库，可测试加法运算：\n1.4-2 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"a35d54b68efc5dcf17c7d7ecbf34edf0","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter1/1.4/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter1/1.4/","section":"courses","summary":"1.安装步骤\n下载地址：https://www.mongodb.com/download-center/community 版本4.4或更高版本；或者网盘下载：https://pan.baidu.com/s/15KwMqxcVFi8D6BpMBKNQkA?pwd=abt7 提取码: abt7 安装方法参考：https://www.runoob.com/mongodb/mongodb-window-install.html 安装过程中不要勾选MongoDB Compass（可视化环境），MongoDB单独安装。 2.配置数据和日志文件目录（自定义）\n创建数据目录：D:\\mongodb\\data\\db 创建日志目录：D:\\mongodb\\data\\log 创建日志文件：D:\\mongodb\\data\\log\\mongodb.log 3.安装成功与否测试\n启动服务器：\nC:\\Program Files\\MongoDB\\Server\\4.4\\bin\u003e.\\mongod.exe --dbpath d:\\mongodb\\data\\db 看到日志倒数第二行：waiting for connections on port 27017\n浏览器输入：http://localhost:27017/\n1.4-1 出现上述情况，说明安装正常 4.MongoDB的后台管理shell（mongo进程）\nMongoDB Shell是MongoDB自带的交互式Javascript shell,用来对MongoDB进行操作和管理的交互式环境。","tags":null,"title":"1.4 安装部署","type":"book"},{"authors":null,"categories":null,"content":"mongod进程\nMongod.exe为启动此数据库实例进程对应的可执行文件，是整个MongoDB中最核心的内容，负责数据库的创建、删除等各项管理工作，运行在服务器端为客户端提供监听，相当于MySQL中的mysqld进程。 mongo进程\nMongo是一个与mongod进程进行交互的JavaScript Shell进程，它提供了一些交互的接口函数用于系统管理员对数据库系统进行管理。 其他进程\nmongodump提供了一种从mongod实例上导出BSON dump文件的方法，mongorestore能够利用这些dump文件重建数据库，常用命令格式如下： mongodump --port 50000 --db eshop --out e:\\bak 参数–port是mongod实例监听端口，–db是数据库名称，–out是备份文件保存目录， mongodump –help查看更多参数。 mongoexport是一个将MongoDB数据库实例中的数据导出来产生JSON或CVS文件的工具； mongoimport是一个将JSON或CVS文件内容导入到MongoDB实例中的工具； mongos是一个在分片中用到的进程。所以应用程序端的查询操作都会先由它分析，然后将查询定位到具体某一个分片上。 mongofiles提供一个操作MongoDB分布式文件存储系统的命令行接口。 mongostat提供一个展示当前正在运行的mongod实例的状态工具。 mongotop提供一个分析MongoDB实例花在读写数据上的时间跟踪方法。 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714310276,"objectID":"ba342d04f6098a20a5ea03f6abff632c","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter1/1.5/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter1/1.5/","section":"courses","summary":"mongod进程\nMongod.exe为启动此数据库实例进程对应的可执行文件，是整个MongoDB中最核心的内容，负责数据库的创建、删除等各项管理工作，运行在服务器端为客户端提供监听，相当于MySQL中的mysqld进程。 mongo进程\nMongo是一个与mongod进程进行交互的JavaScript Shell进程，它提供了一些交互的接口函数用于系统管理员对数据库系统进行管理。 其他进程\nmongodump提供了一种从mongod实例上导出BSON dump文件的方法，mongorestore能够利用这些dump文件重建数据库，常用命令格式如下： mongodump --port 50000 --db eshop --out e:\\bak 参数–port是mongod实例监听端口，–db是数据库名称，–out是备份文件保存目录， mongodump –help查看更多参数。 mongoexport是一个将MongoDB数据库实例中的数据导出来产生JSON或CVS文件的工具； mongoimport是一个将JSON或CVS文件内容导入到MongoDB实例中的工具； mongos是一个在分片中用到的进程。所以应用程序端的查询操作都会先由它分析，然后将查询定位到具体某一个分片上。 mongofiles提供一个操作MongoDB分布式文件存储系统的命令行接口。 mongostat提供一个展示当前正在运行的mongod实例的状态工具。 mongotop提供一个分析MongoDB实例花在读写数据上的时间跟踪方法。 ","tags":null,"title":"1.5几个重要的可执行文件","type":"book"},{"authors":null,"categories":null,"content":"1.高并发web应用程序\nMongoDB支持无固定结构的表模型，容易增加和减少表中的字段，适应业务变化； MongoDB支持分片集群，很容易实现水平扩展，将数据分散到集群中的各个片上，提高了系统存储容量和读写吞吐量； “热数据”读并发高，放在内存中访问更快，MongoDB本身就支持内存映射数据文件。 1.6-1 2.实时计算类应用\n如实时营销，实时推荐； 1.6-2 3.数据中台\n1.6-3 4.游戏类应用\n装备、经验值进程变化 实时数据统计分析、促销等 5.日志分析类系统\n海量日志数据查询快 为大数据分析和决策提供支持 1.6-4 6.AI应用场景\n深度学习输入的数据集，如文本、图像、视频等快速变化 深度学习训练中添加隐藏层、特征标签、超参数和新的输入数据等 银行、电信、石油、汽车、智能家庭等场景 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"2db61d583760958099da38494ded7aec","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter1/1.6/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter1/1.6/","section":"courses","summary":"1.高并发web应用程序\nMongoDB支持无固定结构的表模型，容易增加和减少表中的字段，适应业务变化； MongoDB支持分片集群，很容易实现水平扩展，将数据分散到集群中的各个片上，提高了系统存储容量和读写吞吐量； “热数据”读并发高，放在内存中访问更快，MongoDB本身就支持内存映射数据文件。 1.6-1 2.实时计算类应用\n如实时营销，实时推荐； 1.6-2 3.数据中台\n1.6-3 4.游戏类应用\n装备、经验值进程变化 实时数据统计分析、促销等 5.日志分析类系统\n海量日志数据查询快 为大数据分析和决策提供支持 1.6-4 6.AI应用场景\n深度学习输入的数据集，如文本、图像、视频等快速变化 深度学习训练中添加隐藏层、特征标签、超参数和新的输入数据等 银行、电信、石油、汽车、智能家庭等场景 ","tags":null,"title":"1.6 适合的业务","type":"book"},{"authors":null,"categories":null,"content":"当需要返回集合中文档记录的总条数或者返回不 重复的文档记录时，可以使用 MongoDB 提供 的单个集合中的基础聚集函数.\n1.db.collection.count(query, options)\n返回集合中的文档记录数量； query 为查询条件； options 可选参数，可包含 limit,skip 等； 例如： db.customers.count({cutst_id:100} 2.db.collection.estimatedDocumentCount(options)\n统计集合中的文档记录数量； 只有options可选参数，可包含maxTimeMS(执行统计时允许等待的最大时长)； 例：db.customers.estimatedDocumentCount() 3.db.collection.countDocuments(query, options)\n和count()类似 4.db.collection.distinct(field, query, options)\n返回指定字段的非重复值；\nfield为需要distinct的字段名；\nuery为查询过滤条件；\noptions可选参数，是否区分大小写或字符串比较规则等。\n例如\ndb.books.distinct({“book_id”})\n嵌套字段：db.address.distinct({“location.type”})\n也支持返回数组字段中非重复值。\n4.1-1 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714296140,"objectID":"209f2782fe4676925cb3ea5317e160a0","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter4/4.1/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter4/4.1/","section":"courses","summary":"当需要返回集合中文档记录的总条数或者返回不 重复的文档记录时，可以使用 MongoDB 提供 的单个集合中的基础聚集函数.\n1.db.collection.count(query, options)\n返回集合中的文档记录数量； query 为查询条件； options 可选参数，可包含 limit,skip 等； 例如： db.customers.count({cutst_id:100} 2.db.collection.estimatedDocumentCount(options)\n统计集合中的文档记录数量； 只有options可选参数，可包含maxTimeMS(执行统计时允许等待的最大时长)； 例：db.customers.estimatedDocumentCount() 3.db.collection.countDocuments(query, options)\n和count()类似 4.db.collection.distinct(field, query, options)\n返回指定字段的非重复值；\nfield为需要distinct的字段名；\nuery为查询过滤条件；\noptions可选参数，是否区分大小写或字符串比较规则等。","tags":null,"title":"4.1 单个集合中的基础聚集函数","type":"book"},{"authors":null,"categories":null,"content":"MongoDB的管道聚合框架是参考UNIX上的管道命令实现的，数据通过一个多步骤的管道，每个步骤都会对数据进行加工处理，最后返回需要的结果集。\n管道提供了高效的数据分析流程，是MongoDB中首选的数据分析方法。\n例：\ndb.books.aggregate([ {$match:{status:“normal”}}, {$group:{_id:\u0026#34;$bookid\u0026#34;,total:{$sum:\u0026#34;$num\u0026#34;}}} ])\rA caption A caption A caption 管道聚集的语法格式：\rdb.collection.aggregate(pipeline,options) pipeline为数组类型参数，包含一系列处理步骤，常用的管道操作符有以下几个：\r- $match：过滤文档\r- $limit：限制管道中文件的数据 $skip：跳过指定的文档数量，返回剩下的\r- $sort：对所输入的文档进行排序 $group：对文档进行分组后计算聚集结果 $out：输出文档到新集合中（必须是管道操作的最后一步）\r与$group一起使用的计算聚集操符：\r- $first：返回group操作后的第一个值 $last：返回group操作后的最后一个值 $max：返回group操作后的最大值 $min：返回group操作后的最小值\r- $avg：返回group操作后的平均值 $sum：返回group操作后所有值求和 管道中$group分组语法：\rdb.collection.aggregate([ { $group: { _id: “$itemtype”, \u0026lt; field1\u0026gt;: { \u0026lt; accumulator1\u0026gt; : \u0026lt; expression1\u0026gt; }, … } } ]) - id为必选字段，itemtype为被分组字段, 写成$itemtype，可为空或null;\r- field1自定义返回字段名，为可选计算操作，$sum等， 为计算传递参数\n","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713271828,"objectID":"a1f884bcaf63a19b89eba22b7e81f4e4","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter4/4.2/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter4/4.2/","section":"courses","summary":"MongoDB的管道聚合框架是参考UNIX上的管道命令实现的，数据通过一个多步骤的管道，每个步骤都会对数据进行加工处理，最后返回需要的结果集。\n管道提供了高效的数据分析流程，是MongoDB中首选的数据分析方法。\n例：\ndb.books.aggregate([ {$match:{status:“normal”}}, {$group:{_id:\"$bookid\",total:{$sum:\"$num\"}}} ])\rA caption A caption A caption 管道聚集的语法格式：\rdb.collection.aggregate(pipeline,options) pipeline为数组类型参数，包含一系列处理步骤，常用的管道操作符有以下几个：\r- $match：过滤文档\r- $limit：限制管道中文件的数据 $skip：跳过指定的文档数量，返回剩下的\r- $sort：对所输入的文档进行排序 $group：对文档进行分组后计算聚集结果 $out：输出文档到新集合中（必须是管道操作的最后一步）\r与$group一起使用的计算聚集操符：\r- $first：返回group操作后的第一个值 $last：返回group操作后的最后一个值 $max：返回group操作后的最大值 $min：返回group操作后的最小值\r- $avg：返回group操作后的平均值 $sum：返回group操作后所有值求和 管道中$group分组语法：\rdb.","tags":null,"title":"4.2  管道聚集框架","type":"book"},{"authors":null,"categories":null,"content":"MongoDB提供了当前流行的MapReduce并行编程模型，为海量数据的查询分析提供了一种更加高效的方法。\n用MongoDB做分布式存储，再用MapReduce来做分析。\rMap-Reduce操作有两部分： - 一个map阶段处理每一个文档，并为每一个输入的文档产生一个或多个对象，\n在reduce阶段，对上一步Map产生的输出结果进行合并。\rmap-reduce也可以有一个最终的阶段来对最后的输出结果进行修改，就像其他聚集操作一样 map-reduce能够指定一个查询条件来对输入文档的查询结果进行排序以及部分输出（sort and limit）。 Map-reduce一般采用自定义JavaScript函数来处理map操作与reduce操作以及可选的最后一个最终操作；\r采用自定义的JavaScript能够比管道聚集更灵活，然而一般情况下map-reduce比管道聚集更加低效，也更加复杂。\rMap-reduce进行聚集的示例：\r4.3-1 - 命令：db.orders.mapReduce( function(){emit(this.custid,this.amount);},\rfunction(key,values){return Array.sum(values)},\r{ query:{status:“A”}, out:“order_totals” } )\r- query：查询过滤条件，返回状态为A的值； map：映射对应字段，产生键值对，emit(key,value)； reduce：对map数据进行归约，对数组中value求和； out：输出结果保存在集合order_totals中； 处理流程：query -\u0026gt; map -\u0026gt;reduce\r4.3-2 4.3-3 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713271828,"objectID":"5498effe9a14ab796205c3f7854963ba","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter4/4.3/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter4/4.3/","section":"courses","summary":"MongoDB提供了当前流行的MapReduce并行编程模型，为海量数据的查询分析提供了一种更加高效的方法。\n用MongoDB做分布式存储，再用MapReduce来做分析。\rMap-Reduce操作有两部分： - 一个map阶段处理每一个文档，并为每一个输入的文档产生一个或多个对象，\n在reduce阶段，对上一步Map产生的输出结果进行合并。\rmap-reduce也可以有一个最终的阶段来对最后的输出结果进行修改，就像其他聚集操作一样 map-reduce能够指定一个查询条件来对输入文档的查询结果进行排序以及部分输出（sort and limit）。 Map-reduce一般采用自定义JavaScript函数来处理map操作与reduce操作以及可选的最后一个最终操作；\r采用自定义的JavaScript能够比管道聚集更灵活，然而一般情况下map-reduce比管道聚集更加低效，也更加复杂。\rMap-reduce进行聚集的示例：\r4.3-1 - 命令：db.orders.mapReduce( function(){emit(this.custid,this.amount);},\rfunction(key,values){return Array.sum(values)},\r{ query:{status:“A”}, out:“order_totals” } )\r- query：查询过滤条件，返回状态为A的值； map：映射对应字段，产生键值对，emit(key,value)； reduce：对map数据进行归约，对数组中value求和； out：输出结果保存在集合order_totals中； 处理流程：query -\u003e map -\u003ereduce\r4.","tags":null,"title":"4.3 MapReduce编程","type":"book"},{"authors":null,"categories":null,"content":"存储引擎是什么\n磁盘上的数据读到内存并返回给应用\n将应用修改的数据由内存写到磁盘上\n分类\n一、典型的B—tree数据结构\n5.1-1 在整个B-tree中从上往下依次为根节点、内部节点、叶子节点。每一个节点就是一个page，数据以page为单位在内存和磁盘之间进行调度。每个page的大小决定了相应节点的分支数量，每条索引记录会包含一个数据指针，该指针指向一条数据记录所在文件的偏移量 二、磁盘中的基础数据结构\n5.1-2 三、内存中的基础数据结构\n5.1-3 四、page的其他数据结构\n1、WT_PAGE_MODIFY：用于保存page上的事务、脏数据字节大小等与page修改相关的信息\n2、read_gen 当page中的read generation 值作为evictpage使用时，对应page在LRU队列中的位置，决定page被evictsever选中淘汰出去的先后顺序。\n等等还有很多\n","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715209038,"objectID":"658b781820df303a9745e35150f5cede","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/5.1/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/5.1/","section":"courses","summary":"存储引擎是什么\n磁盘上的数据读到内存并返回给应用\n将应用修改的数据由内存写到磁盘上\n分类\n一、典型的B—tree数据结构\n5.1-1 在整个B-tree中从上往下依次为根节点、内部节点、叶子节点。每一个节点就是一个page，数据以page为单位在内存和磁盘之间进行调度。每个page的大小决定了相应节点的分支数量，每条索引记录会包含一个数据指针，该指针指向一条数据记录所在文件的偏移量 二、磁盘中的基础数据结构\n5.1-2 三、内存中的基础数据结构\n5.1-3 四、page的其他数据结构\n1、WT_PAGE_MODIFY：用于保存page上的事务、脏数据字节大小等与page修改相关的信息\n2、read_gen 当page中的read generation 值作为evictpage使用时，对应page在LRU队列中的位置，决定page被evictsever选中淘汰出去的先后顺序。\n等等还有很多","tags":null,"title":"5.1 存储引擎的数据结构","type":"book"},{"authors":null,"categories":null,"content":"为什么要进行页面淘汰\n为了有足够的内存空间，保障后面新的插入和修改等操作。\n定义\n当内存中的“脏页”达到一定比例或cache使用量达到一定比例时就会触发相应的evict page线程来将pages（包含干净的pages和脏pages）按一定的算法（LRU队列）淘汰出去。 触发page eviction条件的几种参数控制\n5.2-1 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715209038,"objectID":"1c4839124bc9a7a4215e059688b9f6e1","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/5.2/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/5.2/","section":"courses","summary":"为什么要进行页面淘汰\n为了有足够的内存空间，保障后面新的插入和修改等操作。\n定义\n当内存中的“脏页”达到一定比例或cache使用量达到一定比例时就会触发相应的evict page线程来将pages（包含干净的pages和脏pages）按一定的算法（LRU队列）淘汰出去。 触发page eviction条件的几种参数控制\n5.2-1 ","tags":null,"title":"5.2 page eviction进行页面淘汰","type":"book"},{"authors":null,"categories":null,"content":"注意\n页面淘汰之前，通过reconcile生成磁盘映像page大小，并写入磁盘\n流程图\n5.3-1 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715209038,"objectID":"bef0fc63ec4acff7b8af72267366a996","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/5.3/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/5.3/","section":"courses","summary":"注意\n页面淘汰之前，通过reconcile生成磁盘映像page大小，并写入磁盘\n流程图\n5.3-1 ","tags":null,"title":"5.3 page reconcile将数据写入磁盘","type":"book"},{"authors":null,"categories":null,"content":"规则 WiredTiger启动时，向操作系统申请一部分内存称Internal Cache，如果主机上只运行MongoDB相关的服务进程，则剩下的内存可以作为文件系统的缓存并由操作系统负责管理。 整个内存使用情况如下图 5.4-1 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715209038,"objectID":"a8cf4ba4e6d45b61d41b7ef235a71d26","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/5.4/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/5.4/","section":"courses","summary":"规则 WiredTiger启动时，向操作系统申请一部分内存称Internal Cache，如果主机上只运行MongoDB相关的服务进程，则剩下的内存可以作为文件系统的缓存并由操作系统负责管理。 整个内存使用情况如下图 5.4-1 ","tags":null,"title":"5.4 内存的分配规则","type":"book"},{"authors":null,"categories":null,"content":"步骤\n第一步：pages从磁盘读到内存\n第二步：pages在内存中被修改\n第三步：被修改的脏pages在内存被reconcile，完成后将discard这些pages。\n第四步：pages被选中，加入淘汰队列，等待被evict线程淘汰出内存\n第五步：evict线程会将干净的pages直接从内存丢弃（page没修改），将经过reconcile处理后的磁盘映像写到磁盘再丢弃“脏的”pages。\n流程图\n5.5-1 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715209038,"objectID":"01b6e529649d18a3ffd9dee5a64cd39d","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/5.5/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/5.5/","section":"courses","summary":"步骤\n第一步：pages从磁盘读到内存\n第二步：pages在内存中被修改\n第三步：被修改的脏pages在内存被reconcile，完成后将discard这些pages。\n第四步：pages被选中，加入淘汰队列，等待被evict线程淘汰出内存\n第五步：evict线程会将干净的pages直接从内存丢弃（page没修改），将经过reconcile处理后的磁盘映像写到磁盘再丢弃“脏的”pages。\n流程图\n5.5-1 ","tags":null,"title":"5.5 page的生命周期","type":"book"},{"authors":null,"categories":null,"content":"使用checkpoint的目的\n一、是将内存里面发生修改的数据写到数据文件进行持久化保存，确保数据一致性\n二、是实现数据库在某个时刻意外发生故障，再次启动时，缩短数据库的恢复时间\ncheckpoint本质\nCheckpoint相当于一个日志，记录了上次Checkpoint后相关数据文件的变化\ncheckpoint包含的关键信息\n先看图\n5.6-1 每一个checkpoint包含1个root、3个列表及磁盘文件大小\n详细信息解释:\n(1)root page:包含root page 的大小(size)、在文件中的位置(offset)、校验和(checksum)，当创建一checkpoint时，会生成一个新 root page。\n(2)allocated list page:用于记录最后一次 checkpoint之后，在这次 checkpoint执行时,由WiredTiger块管理器新分配的page记录每个新分配page的size、offset和checksum\n(3)available list page:在执行这次 checkpoint时，所有由WiredTiger 块管理器分配的page还没有被使用;当删除一个之前创建的checkpoint时，它所附带的可用 page 将被合并到最新的checkpoint的可用列表上，也会记录每个可用page的size、offset 和checksum.\n(4)discarded list page:用于记录最后一次 checkpoint之后，在这次 checkpoint 执行时，丢弃不再使用的page，并会记录每个丢弃page的size、offset和checksume\n(5)fle size:在这次 checkpoint执行后，用于记录磁盘中数据文件的大小。\ncheckpoint原理图\n5.6-2 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715209038,"objectID":"c9c514304707a33933ac451616dd3f8d","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/5.6/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/5.6/","section":"courses","summary":"使用checkpoint的目的\n一、是将内存里面发生修改的数据写到数据文件进行持久化保存，确保数据一致性\n二、是实现数据库在某个时刻意外发生故障，再次启动时，缩短数据库的恢复时间\ncheckpoint本质\nCheckpoint相当于一个日志，记录了上次Checkpoint后相关数据文件的变化\ncheckpoint包含的关键信息\n先看图\n5.6-1 每一个checkpoint包含1个root、3个列表及磁盘文件大小\n详细信息解释:\n(1)root page:包含root page 的大小(size)、在文件中的位置(offset)、校验和(checksum)，当创建一checkpoint时，会生成一个新 root page。\n(2)allocated list page:用于记录最后一次 checkpoint之后，在这次 checkpoint执行时,由WiredTiger块管理器新分配的page记录每个新分配page的size、offset和checksum\n(3)available list page:在执行这次 checkpoint时，所有由WiredTiger 块管理器分配的page还没有被使用;当删除一个之前创建的checkpoint时，它所附带的可用 page 将被合并到最新的checkpoint的可用列表上，也会记录每个可用page的size、offset 和checksum.\n(4)discarded list page:用于记录最后一次 checkpoint之后，在这次 checkpoint 执行时，丢弃不再使用的page，并会记录每个丢弃page的size、offset和checksume","tags":null,"title":"5.6  checkpoint的原理","type":"book"},{"authors":null,"categories":null,"content":"wt工具用于何处\nWiredTiger生成的磁盘文件基本上是二进制格式，我们并不能直接用编辑工具打开阅读，如果想查看相关元数据，可以用WiredTiger提供的wt工具\n需自行下载编译，linux环境\n元数据相关文件 collection-xxx.wt和index-xxx.wt，数据库中集合所对应的数据文件和索引文件；\nWiredTiger.lock，运行实例的锁文件\nmongod.lock，锁文件\nstorage.bson，配置文件\nsizeStorer.wt，文档容量信息 5.7-1 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715209038,"objectID":"c3264800611398e61dad59f92652ff47","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/5.7/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/5.7/","section":"courses","summary":"wt工具用于何处\nWiredTiger生成的磁盘文件基本上是二进制格式，我们并不能直接用编辑工具打开阅读，如果想查看相关元数据，可以用WiredTiger提供的wt工具\n需自行下载编译，linux环境\n元数据相关文件 collection-xxx.wt和index-xxx.wt，数据库中集合所对应的数据文件和索引文件；\nWiredTiger.lock，运行实例的锁文件\nmongod.lock，锁文件\nstorage.bson，配置文件\nsizeStorer.wt，文档容量信息 5.7-1 ","tags":null,"title":"5.7 wt工具和磁盘中的元数据","type":"book"},{"authors":null,"categories":null,"content":"事务的基本原理\n原子性：要么完全执行成功，要么不做任何改变；\n一致性：当多个事务并行执行时，元素的属性在每个事务中保持一致；\n隔离性：当多个事务同时执行时，互不影响；\n持久性：一旦提交事务，数据的更改就不会丢失。\n事务的数据结构 事务在内存里面也会维护相应的数据结构以支撑事务的并发、回滚、持久化等操作\n5.8-1 字段解释\n(1)id字段:这是事务的全局唯一标识，通过分析它与具体的操作关联，就能够知道一个事务包含哪些操作。\n(2)snapshot data 字段:MongoDB 使用的是快照隔离级别的事务，这个字段用于保存事务的快照信息，具体来说它会有 snap_min和 snap_max两个属性，通过这两个属性能够计算一个事务开始时的数据范围，每个事务开始时都会构造一个这样的快照.\n(3)commit_timestamp字段:表示事务提交的时间， (4)durable_timestamp字段:表示事务修改的数据已持久化的时间，与具体操作中的 durable_ts 字段关联。 (5)prepare timestamp字段:表示事务开始准备的时间\n(6)WT_TXN_OP字段:包含事务的修改操作，用于事务回滚和生成事务日志( Journal )。 (7)1ogrec字段:表示事务日志的缓存，用于在内存中保存事务日志(对于MongoDB来说 Journal日志就是事务日志)。\n","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715209038,"objectID":"7c89fba0cd1b60ddfb4bd93d06dc61b3","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter5/5.8/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter5/5.8/","section":"courses","summary":"事务的基本原理\n原子性：要么完全执行成功，要么不做任何改变；\n一致性：当多个事务并行执行时，元素的属性在每个事务中保持一致；\n隔离性：当多个事务同时执行时，互不影响；\n持久性：一旦提交事务，数据的更改就不会丢失。\n事务的数据结构 事务在内存里面也会维护相应的数据结构以支撑事务的并发、回滚、持久化等操作\n5.8-1 字段解释\n(1)id字段:这是事务的全局唯一标识，通过分析它与具体的操作关联，就能够知道一个事务包含哪些操作。\n(2)snapshot data 字段:MongoDB 使用的是快照隔离级别的事务，这个字段用于保存事务的快照信息，具体来说它会有 snap_min和 snap_max两个属性，通过这两个属性能够计算一个事务开始时的数据范围，每个事务开始时都会构造一个这样的快照.\n(3)commit_timestamp字段:表示事务提交的时间， (4)durable_timestamp字段:表示事务修改的数据已持久化的时间，与具体操作中的 durable_ts 字段关联。 (5)prepare timestamp字段:表示事务开始准备的时间\n(6)WT_TXN_OP字段:包含事务的修改操作，用于事务回滚和生成事务日志( Journal )。 (7)1ogrec字段:表示事务日志的缓存，用于在内存中保存事务日志(对于MongoDB来说 Journal日志就是事务日志)。","tags":null,"title":"5.8  事务","type":"book"},{"authors":null,"categories":null,"content":" 复制集Replica Sets与分片集群sharding是MongoDB最具有特色的功能： 复制集实现了数据库的冗余备份、故障转移，这是数据库管理人员最求的目标； 分片实现了数据的分布式存储、负载均衡，这是海量数据云存储平台不可或缺的功能。 数据库总是会遇到各种失败的场景，如网络连接断开、断电等，尽管journaling日志功能也提供了数据恢复的功能，但journaling通常是针对单个节点来说的，只能保证单节点数据的一致性；\n复制集通常是由多个节点组成，每个节点除了journaling日志恢复功能外，整个复制集还具有故障自动转移的功能，这样能保证数据库的高可用性。\n在生产环境中一个复制集最少应该包含三个节点，其中有一个必须是主节点，典型的部署结构如下图：\n6.1-1 每个节点都是一个mongod进程对应的实例，节点之间互相周期性的通过心跳检查对方的状态，默认情况下primary节点负责数据的读、写，second节点备份primary节点上的数据，但是arbiter节点不会从primary节点同步数据；\n从它的名字arbiter可以看出，它起到的作用只是当primary节点故障时，能够参与到复制集剩下的节点中**，选择出一个新**的primary节点，它自己永远不会变为primary节点，也不会参与数据的读写。也就是说，数据库的数据会存在primary和second节点中，second节点相当于一个备份，当然second节点可以有多个，当primary节点故障时，second节点有可能变为primary节点。故障转移流程如图所示。\n6.1-2 更多复制集的概念和原理可参考如下链接：\nhttps://www.cnblogs.com/duanxz/p/10730096.html\nhttps://blog.csdn.net/qq_24598601/article/details/81150614\nhttps://docs.mongodb.com/manual/replication/\n","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714185706,"objectID":"414c91c1dfaa92cd520264f85fc8b9c3","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter6/6.1/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter6/6.1/","section":"courses","summary":"复制集Replica Sets与分片集群sharding是MongoDB最具有特色的功能： 复制集实现了数据库的冗余备份、故障转移，这是数据库管理人员最求的目标； 分片实现了数据的分布式存储、负载均衡，这是海量数据云存储平台不可或缺的功能。 数据库总是会遇到各种失败的场景，如网络连接断开、断电等，尽管journaling日志功能也提供了数据恢复的功能，但journaling通常是针对单个节点来说的，只能保证单节点数据的一致性；\n复制集通常是由多个节点组成，每个节点除了journaling日志恢复功能外，整个复制集还具有故障自动转移的功能，这样能保证数据库的高可用性。\n在生产环境中一个复制集最少应该包含三个节点，其中有一个必须是主节点，典型的部署结构如下图：\n6.1-1 每个节点都是一个mongod进程对应的实例，节点之间互相周期性的通过心跳检查对方的状态，默认情况下primary节点负责数据的读、写，second节点备份primary节点上的数据，但是arbiter节点不会从primary节点同步数据；\n从它的名字arbiter可以看出，它起到的作用只是当primary节点故障时，能够参与到复制集剩下的节点中**，选择出一个新**的primary节点，它自己永远不会变为primary节点，也不会参与数据的读写。也就是说，数据库的数据会存在primary和second节点中，second节点相当于一个备份，当然second节点可以有多个，当primary节点故障时，second节点有可能变为primary节点。故障转移流程如图所示。\n6.1-2 更多复制集的概念和原理可参考如下链接：\nhttps://www.cnblogs.com/duanxz/p/10730096.html\nhttps://blog.csdn.net/qq_24598601/article/details/81150614\nhttps://docs.mongodb.com/manual/replication/","tags":null,"title":"6.1复制集概述","type":"book"},{"authors":null,"categories":null,"content":"复制集的创建和配置：\n创建复制集中每个节点存放数据的目录 D:\\mongodb\\db_rs0\\data\\rs0_0\nD:\\mongodb\\db_rs0\\data\\rs0_1\nD:\\mongodb\\db_rs0\\data\\rs0_2\n创建复制集中每个节点的日志文件 D:\\mongodb\\db_rs0\\logs\\rs0_0.log\nD:\\mongodb\\db_rs0\\logs\\rs0_1.log\nD:\\mongodb\\db_rs0\\logs\\rs0_2.log\n创建复制集中每个节点启动时的配置文件 第一个节点配置文件为：\nD:\\mongodb\\configs_rs0\\rs0_0.conf，内容如下：\ndbpath = D:\\mongodb\\db_rs0\\data\\rs0_0 logpath = D:\\mongodb\\db_rs0\\logs\\rs0_0.log journal = true port = 40000 replSet = rs0 第二个节点配置文件为：\nD:\\mongodb\\configs_rs0\\rs0_1.conf，内容如下：\ndbpath = D:\\mongodb\\db_rs0\\data\\rs0_1 logpath = D:\\mongodb\\db_rs0\\logs\\rs0_1.log journal = true port = 40001 replSet = rs0 第三个节点配置文件为：\nD:\\mongodb\\configs_rs0\\rs0_2.conf，内容如下：\ndbpath = D:\\mongodb\\db_rs0\\data\\rs0_2 logpath = D:\\mongodb\\db_rs0\\logs\\rs0_2.log journal = true port = 40002 replSet = rs0 启动上面三个节点对应的MongoDB实例 .\\mongod.exe --config D:\\mongodb\\configs_rs0\\rs0_0.conf\n.\\mongod.exe --config D:\\mongodb\\configs_rs0\\rs0_1.conf\n.\\mongod.exe --config D:\\mongodb\\configs_rs0\\rs0_2.conf\n未报错即启动成功。\n6.2-1 启动一个mongo客户端，连接到MongoDB实例 因为第四步复制集没有配置好，还需要确定哪个节点为primary，哪个是second，哪个是arbiter;\n.\\mongo.exe --port 40000 //启动客户端并连接到40000\n6.2-2 rs.initiate() //初始化复制集，出现ok: 1即成功\n这时候复制集只有刚才40000这个初始化成员，通过如下命令可查看信息：\nrs.conf()\n默认情况下，刚才配置的节点为primary节点\n在复制集中添加second和arbiter节点，继续执行如下命令： rs0.PRIMARY\u0026gt; rs.add(“localhost:40001”)\n出现ok：1即成功\nrs0.PRIMARY\u0026gt; rs.addArb(“localhost:40002”)\n出现ok：1即成功\n两个节点添加成功。\n观察整个复制集的状态信息： rs.status() 6.2-3 6.2-4 6.2-5 复制集的状态信息输出是基于primary节点实例的，在secondary实例上也可以输出复制集的状态信息。 arbiter节点的“syncingTo” : “”为空，说明不需要从primary节点上同步数据； 当主节点出现故障时，arbiter节点为仲裁节点，也称为选举节点，可辅助从secondary中选举主节点，不需要占用太多存储空间。 “date”表示当前实例所在服务器的时间； “lastHeartbeat”表示当前实例到此远端成员最近一次成功发送与接收心跳包的时间； 通过比较这个两个时间可以判断当前实例与此成员相差的时间间隔； 比如某个成员宕机了，本实例发生此宕机成员的心跳包就不会被成功接收，随着时间推移，本实例的date字段值与此成员上的lastHeartbeat差值就会逐渐增加。 optime字段，这个字段的值说明了本实例最近一次更改数据库的时间“t” : 1376816431以及每秒执行的操作数据库的次数“i” : 1； 此字段的值实际上是从本实例上的local数据库中的oplog.rs集合上读取的，这个集合还详细记录了具体是什么操作，如插入语句、修改语句等。 复制集中的每一个实例都会有一个这样的数据库和集合，如果复制集运行正常，理论上来说，每一个mongod实例上此集合中的记录应该相同。 实际上mongoDB也是根据此集合来实现复制集中primary节点与secondary节点间的数据同步。 ","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714185496,"objectID":"7af03991323964481fa2e64d12bdf33a","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter6/6.2/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter6/6.2/","section":"courses","summary":"复制集的创建和配置：\n创建复制集中每个节点存放数据的目录 D:\\mongodb\\db_rs0\\data\\rs0_0\nD:\\mongodb\\db_rs0\\data\\rs0_1\nD:\\mongodb\\db_rs0\\data\\rs0_2\n创建复制集中每个节点的日志文件 D:\\mongodb\\db_rs0\\logs\\rs0_0.log\nD:\\mongodb\\db_rs0\\logs\\rs0_1.log\nD:\\mongodb\\db_rs0\\logs\\rs0_2.log\n创建复制集中每个节点启动时的配置文件 第一个节点配置文件为：\nD:\\mongodb\\configs_rs0\\rs0_0.conf，内容如下：\ndbpath = D:\\mongodb\\db_rs0\\data\\rs0_0 logpath = D:\\mongodb\\db_rs0\\logs\\rs0_0.log journal = true port = 40000 replSet = rs0 第二个节点配置文件为：\nD:\\mongodb\\configs_rs0\\rs0_1.conf，内容如下：\ndbpath = D:\\mongodb\\db_rs0\\data\\rs0_1 logpath = D:\\mongodb\\db_rs0\\logs\\rs0_1.","tags":null,"title":"6.2完整部署一个复制集","type":"book"},{"authors":null,"categories":null,"content":"6.3.1 数据同步 6.1节概述了复制集，整体上对复制集有了个概念，但是复制集最重要的功能：\n数据同步又是如何实现的？ 自动故障转移是怎么实现的呢？ 利用mongo客户端登录到复制集的primary节点上。 \u0026gt;.\\mongo.exe --port 40000\n查看实例上的数据库rs0:PRIMARY\u0026gt; show dbs，可以看到默认的数据库\n默认的数据库 rs0:PRIMARY\u0026gt; use local //使用本地数据库\nlocal数据库为复制集所有成员节点上默认创建的数据库，可以查看上面的集合：\nrs0:PRIMARY\u0026gt; show collections 集合 利用mongo客户端登录到复制集的secondary节点上。 \u0026gt;.\\mongo.exe --port 40001，数据库集合内容是一样的\n主节点集合 次节点集合 oplog.rs是实现复制集之间数据同步的\nreplset.election: 复制集选举信息\nreplset.minvalid:内部使用，跟踪复制状态\nsystem.replset副本集的配置信息，和使用rs.conf()命令看到的一样\n注：在secondary节点上出现not master and slaveOk=false错误时，输入：\nrs0:SECONDARY\u0026gt; rs.slaveOk() 为了分析复制集节点上数据的变化，先在复制集上的primary节点上创建一个数据库students，然后插入一条记录：\nrs0:PRIMARY\u0026gt; use students\nrs0:PRIMARY\u0026gt;db.scores.insert({\u0026#34;stuid\u0026#34;:1,\u0026#34;subject\u0026#34;:\u0026#34;math\u0026#34;,\u0026#34;score\u0026#34;:99})\n接着查看一下primary节点上oplog.rs集合的内容：\nrs0:PRIMARY\u0026gt; use local rs0:PRIMARY\u0026gt;db.oplog.rs.find({“op”:“i”})//筛选出插入操作的内容 查看过程 里面有几个重要字段，其中\u0026#34;ts\u0026#34;表示是这条记录的时间截，“t\u0026#34;是秒数，“i\u0026#34;每秒操作的次数； 字段\u0026#34;op\u0026#34;表示的是操作码，值为\u0026#34;i\u0026#34;表示的是insert操作； “ns\u0026#34;表示插入操作发生的命名空间，这里值为: “students.scores”，由数据库和集合名构成； “o\u0026#34;表示的是此插入操作包含的文档对象； 查看secondary节点上的数据，我们发现在secondary节点上新插入了一个数据库students，这就实现了复制集建的数据同步\nrs0:SECONDARY\u0026gt; show dbs rs0:SECONDARY\u0026gt; use students rs0:SECONDARY\u0026gt; db.scores.find() 次节点数据库同步 同步流程\n同步图解 当primary节点完成插入操作后，secondary节点为了保证数据的同步也会完成一些动作 a.所有secondary节点检查自己的local数据上oplog.rs集合，找出最近的一条记录的时间截 b.接着它会查询primary节点上的oplog.rs集合，找出所有大于此时间截的记录 c.最后它将这些找到的记录插入到自己的oplog.rs集合中并执行这些记录所代表的操作 通过这三步策略，就能保证secondary节点上的数据与primary节点上的数据同步了 关于oplog.rs集合还有一个很重要的方面，那就是它的大小是固定的：\n假如大小没限制，那么随着时间的推移，在数据库上的操作会逐渐累积，oplog.rs集合中保存的记录也会逐渐增多，这样会消耗大量的存储空间 同时对于某个时间点以前的操作记录，早已同步到secondary节点上，也没有必要一直保存这些记录 因此mongoDB将oplog.rs集合设置成一个capped类型的集合，实际上就是一个循环使用的缓冲区 固定大小的oplog.rs会带来新的问题，考虑下面这种场景：\n假如一个secondary节点因为宕机，长时间不能恢复，而此时大量的写操作发生在primary节点上，当secondary节点恢复时，利用自己oplog.rs集合上最新的时间截去查找primary节点上的oplog.rs集合，会出现找不到任何记录。 因为长时间不在线，primary节点上的oplog.rs集合中的记录早已全部刷新了一遍，这样就不得不手动重新同步数据了。 因此oplog.rs的大小是很重要，在32位的系统上默认大小是50MB，在64位的机器上默认是5%的空闲磁盘空间大小，也可以在mongod启动命令中通过项—oplogSize设置其大小\n6.3.2 故障转移 在复制集中的心跳\u0026#34;lastHeartbeat\u0026#34;字段，mongoDB就是靠它来实现自动故障转移的。\nmongod实例每隔2秒就向其它成员发送一个心跳包以及通过rs.status()中返回的成员的“health”值来判断成员的状态。\n如果出现复制集中primary节点不可用了，那么复制集中所有secondary的节点就会触发一次选举操作，选出一个新的primary节点。\n如上所配置的复制集中如果primary节点宕机了，那么就会选举secondary节点成为primary节点，arbiter节点只是参与选举其它成员成为primary节点，自己永远不会成为primary节点。\n如果secondary节点有多个则会选择拥有最新时间截的oplog记录或较高权限的节点成为primary节点。\n如果是某个secondary节点失败了，只要复制集中还有其它secondary节点或arbiter节点存在，就不会发生重新选举primary节点的过程。\n下面模拟两种失败场景：\n一是secondary节点的失败，然后过一段时间后重启（时间不能无限期，否则会导致oplog.rs集合严重滞后的问题，需要手动才能同步）。以下为步骤：\n1.查看当前复制集的配置情况\nrs0:PRIMARY\u0026gt; rs.conf()\n2.通过Kill掉secondary节点所在的mongod实例，模拟第一种故障情况。\n通过rs.status()命令查看复制集状态，secondary节点状态“health” : 0；\n3.接着通过primary节点插入一条记录\nrs0:PRIMARY\u0026gt;db.scores.insert({stuid:2,subject:\u0026#34;english\u0026#34;,score:100})\n4.再次查看复制集状态信息rs.status()，可以看到primary成员节点上oplpog信息\n与上面down机的成员节点比较，optime已经不一样，primary节点上要新于down机的节点。\n5.重新启动Kill掉的secondary节点\n.\\mongod.exe --config D:\\mongodb\\configs_rs0\\rs0_1.conf 查询复制集状态信息rs.status()，观看节点“40001”的状态信息 说明secondary节点已经恢复，并且从primary节点同步到了最新的操作数据 6.登录secondary节点来查询\nrs0:SECONDARY\u0026gt; use students rs0:SECONDARY\u0026gt; db.scores.find() 以下第二条记录正是在primary节点上插入的记录，再次证明数据确实同步过来了。\n插入记录 二是primary节点故障模拟\n1.将primary节点Kill掉，并查询rs.status()，主节点以及宕机。\n字段\u0026#34;health\u0026#34;的值为0，说明原来的primary节点已经down机了。 原来secondary节点变成了primary节点。 2.在新的primary节点上插入一条记录\nrs0:PRIMARY\u0026gt;db.scores.insert({stuid:3,subject:\u0026#34;computer\u0026#34;,score:99}) 3.重新恢复\u0026#34;40000\u0026#34;节点（原来的primary节点）\n.\\mongod.exe --config D:\\mongodb\\configs_rs0\\rs0_0.conf 再次查看复制集状态rs.status() “40000”实例被重新激活后，变成了secondary节点，oplog也被同步成最新的了。 说明当primary节点故障时，复制集能自动转移故障，将其中一个secondary节点变为primary节点，读写操作继续在新的primary节点上进行。原来primary节点恢复后，在复制集中变成了secondary节点。\n数据同步原理 上面两中情况都得到了验证，但是有一点要注意，mongDB默认情况下只能在primary节点上进行读写操作，如下图所示：\n图示 对于客户端应用程序来说，对复制集的读写操作是透明的，默认情况它总是在primary节点上进行。\nmongoDB提供了很多种常见编程语言的驱动程序，驱动程序位于应用程序与mongod实例之间，应用程发起与复制集的连接，驱动程序自动选择primary节点。\n当primary节点失效，复制集发生故障转移时，复制集将先关闭与所有客户端的socket连接，驱动程序将返回一个异常，应用程序收到这个异常，这个时候需要应用程序开发人员去处理这些异常，同时驱动程序会尝试重新与primary节点建立连接（这个动作对应用程序来说是透明的）。\n假如这个时候正在发生一个读操作，在异常处理中你可以重新发起读数据命令，因为读操作不会改变数据库的数据；\n假如这个时候发生的是写操作，情况就变得微妙起来，\n如果是非安全模式下的写，就会产生不确定因素，写是否成功不确定。 如果是安全模式，驱动程序会通过getlasterror命令知道哪些写操作成功了，哪些失败，驱动程序会返回失败的信息给应用程序，针对这个异常信息，应用程序可以决定怎样处置这个写操作，可以重新执行写操作，也可以直接给用户报出这个错误。 6.3.3 写关注 对于某些应用程序来说，写关注是重要的。它能判断哪些写操作成功写入了，哪些失败了，对于失败的操作，驱动程序能返回错误，由应用程序决定怎么处理。\n如果没有写关注，应用程序发送一个写操作到socket后，就不会管后面发生了什么情况，不知道是否成功写入数据库，这种情形对于日志类型的应用程序还是可以接受的，因为偶尔的写失败不会影响整个日志的监控情况。\n带有写关注的操作会等到数据库确认成功写入后才能返回，因此写关注会带来一点性能的损失。下面先分析复制集上写关注配置。\n默认情况下复制集的写关注只针对primary节点，如下图所示:\n图示 w参数\n为0时，不使用写关注，不需要等待就返回。 为1时，只关注primary节点返回确认写成功的消息。 为n时，写关注将针对复制集中n个节点，当客户端收到这些节点的反馈信息后，才能返回确认写成功的消息。 为majority时，取决于复制集中大多数投票节点的数量。 w=2的写关注执行流程图\n流程图 6.3.4 读参考 读参考是指MongoDB将客户端的读请求路由到复制集中指定的成员上，默认情况下读操作的请求被路由到复制集中的primary节点上；\n从Primary节点上进行读取能够保证读到的数据是最新的，但是将读操作路由到其他secondary节点上去后，由于从primary节点同步数据到secondary节点会产生时间差，可能导致从secondary节点上读到的数据不是最新的。当然这对于实时性要求不是很高的绝大部分应用程序来说，并不是大问题。\n关于读参考还有一点需要注意，因为每一个secondary节点都会从primary节点同步数据，所有secondary节点一般有相同的写操作流量，同时primary节点上的读操作流量也并没有减少，所以读参考并不能提高系统读写的容量。\n它最大的好处是能够使客户端的读请求路由到最佳的secondary节点上(如最近的节点)，提高客户端的读效率。\nMongoDB驱动支持的读参考模式如下：\nprimary模式 这是默认的读操作模式，所有的读请求都路由到复制集中的primary节点上，如果primary节点故障了，读操作将会产生一个错误或者抛出一个 …","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714293008,"objectID":"7101f1b9633035e4750d79f498c1336f","permalink":"https://fanfanshen.github.io/courses/bigdatastorage/chapter6/6.3/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/courses/bigdatastorage/chapter6/6.3/","section":"courses","summary":"6.3.1 数据同步 6.1节概述了复制集，整体上对复制集有了个概念，但是复制集最重要的功能：\n数据同步又是如何实现的？ 自动故障转移是怎么实现的呢？ 利用mongo客户端登录到复制集的primary节点上。 \u003e.\\mongo.exe --port 40000\n查看实例上的数据库rs0:PRIMARY\u003e show dbs，可以看到默认的数据库\n默认的数据库 rs0:PRIMARY\u003e use local //使用本地数据库\nlocal数据库为复制集所有成员节点上默认创建的数据库，可以查看上面的集合：\nrs0:PRIMARY\u003e show collections 集合 利用mongo客户端登录到复制集的secondary节点上。 \u003e.\\mongo.exe --port 40001，数据库集合内容是一样的\n主节点集合 次节点集合 oplog.rs是实现复制集之间数据同步的\nreplset.election: 复制集选举信息","tags":null,"title":"6.3 单字段索引","type":"book"},{"authors":["沈凡凡","何炎祥","张军","江南","李清安","李建华"],"categories":[],"content":"","date":1496917263,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"cff1eb4a9f298b57a9ddea5e9c7187b1","permalink":"https://fanfanshen.github.io/publication/2017computer/","publishdate":"2023-10-08T18:21:03+08:00","relpermalink":"/publication/2017computer/","section":"publication","summary":"","tags":[],"title":"一种SRAM辅助新型非易失性缓存的磨损均衡方法","type":"publication"},{"authors":["Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701863083,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://fanfanshen.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"}]